{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import cv2\n",
    "import os\n",
    "os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"]=\"1\"\n",
    "s=cv2.imread('/mnt/Personal/Projects/Python/Autofocus/test.exr',  cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH)  \n",
    "print(type(s))\n",
    "print(numpy.percentile(s,84.44357))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first import os and enable the necessary flags to avoid cv2 errors\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"]=\"1\"\n",
    "import cv2\n",
    "\n",
    "# then just type in following\n",
    "\n",
    "\n",
    "\n",
    "img=cv2.imread('/mnt/Velocity Vault/test.exr',  cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH)  \n",
    "'''\n",
    "you might have to disable following flags, if you are reading a semantic map/label then because it will convert it into binary map so check both lines and see what you need\n",
    "''' \n",
    "# img = cv2.imread(PATH2EXR) \n",
    " \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def display_txt_files_contents(directory):\n",
    "    file_count = 0\n",
    "    try:\n",
    "        # Walk through the directory and all subdirectories\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            # Filter out .txt files\n",
    "            txt_files = [f for f in files if f.endswith('.txt')]\n",
    "            \n",
    "            # Read and display the contents of each .txt file\n",
    "            for txt_file in txt_files:\n",
    "                file_path = os.path.join(root, txt_file)\n",
    "                with open(file_path, 'r') as file:\n",
    "                    print(f\"Contents of {file_path}:\\n\")\n",
    "                    print(file.read())\n",
    "                    print(\"\\n\" + \"-\"*40 + \"\\n\")\n",
    "                file_count += 1\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        print(f\"Number of .txt files processed: {file_count}\")\n",
    "\n",
    "# Example usage\n",
    "directory_path = '/mnt/Velocity Vault/Personal/Projects/Python/Autofocus/Train'\n",
    "display_txt_files_contents(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def parse_file_content(file_path):\n",
    "    data = {\n",
    "        'pos': [],\n",
    "        'orien': [],\n",
    "        'f': None,\n",
    "        'par': None,\n",
    "        'pp': [],\n",
    "        'rd': [],\n",
    "        'skew': None,\n",
    "        'size': [],\n",
    "        'pt': None\n",
    "    }\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            key, value = line.strip().split(': ')\n",
    "            if key == 'position':\n",
    "                data['pos'].append(float(value))\n",
    "            elif key == 'orientation':\n",
    "                data['orien'].append(float(value))\n",
    "            elif key == 'focal_length':\n",
    "                data['f'] = float(value)\n",
    "            elif key == 'pixel_aspect_ratio':\n",
    "                data['par'] = int(value)\n",
    "            elif key == 'principal_point':\n",
    "                data['pp'].append(float(value))\n",
    "            elif key == 'radial_distortion':\n",
    "                data['rd'].append(float(value))\n",
    "            elif key == 'skew':\n",
    "                data['skew'] = int(value)\n",
    "            elif key == 'size_x':\n",
    "                data['size'].append(int(value))\n",
    "            elif key == 'size_y':\n",
    "                data['size'].append(int(value))\n",
    "            elif key == 'projection_type':\n",
    "                data['pt'] = value\n",
    "\n",
    "    return data\n",
    "\n",
    "def create_scale_dictionary(directory):\n",
    "    scale = {}\n",
    "    txt_file_count = 0\n",
    "\n",
    "    try:\n",
    "        # Walk through the directory and all subdirectories\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            # Filter out .txt files\n",
    "            txt_files = [f for f in files if f.startswith('result_scaled_camera_post_') and f.endswith('.txt')]\n",
    "            \n",
    "            for txt_file in txt_files:\n",
    "                txt_file_count += 1\n",
    "                file_path = os.path.join(root, txt_file)\n",
    "                \n",
    "                # Determine the key ('center', 'left', 'right', 'top', 'bottom')\n",
    "                if 'center' in txt_file:\n",
    "                    key = 'center'\n",
    "                elif 'left' in txt_file:\n",
    "                    key = 'left'\n",
    "                elif 'right' in txt_file:\n",
    "                    key = 'right'\n",
    "                elif 'top' in txt_file:\n",
    "                    key = 'top'\n",
    "                elif 'bottom' in txt_file:\n",
    "                    key = 'bottom'\n",
    "                else:\n",
    "                    key = txt_file  # Default to full filename if none of the above matches\n",
    "\n",
    "                # Split the path to get <something1>, <number>, <something2>\n",
    "                parts = file_path.split(os.sep)\n",
    "                something1, num, something2 = parts[-3], parts[-2], parts[-1].replace('.txt', '')\n",
    "                number=int(num)\n",
    "\n",
    "                # Ensure the nested dictionary structure exists\n",
    "                if something1 not in scale:\n",
    "                    scale[something1] = {}\n",
    "                if number not in scale[something1]:\n",
    "                    scale[something1][number] = {}\n",
    "\n",
    "                # Store the parsed file content under the appropriate key\n",
    "                scale[something1][number][key] = parse_file_content(file_path)\n",
    "\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    return scale,txt_file_count\n",
    "\n",
    "# # Example usage\n",
    "# directory_path = '/mnt/Velocity Vault/Personal/Projects/Python/Autofocus/Train/train1'\n",
    "# scale,file_count = create_scale_dictionary(directory_path)\n",
    "# print(f\"Number of .txt files processed: {file_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def create_camera_pose_dict(directory):\n",
    "    camera_pose = {}\n",
    "    file_count=0\n",
    "    \n",
    "    try:\n",
    "        # Get list of directories (folders) in the specified directory\n",
    "        directories = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
    "        \n",
    "        # Extract numbers from directory names and create empty dictionary entries\n",
    "        for d in directories:\n",
    "            if d.startswith('train'):\n",
    "                number = int(d[5:])  # Extract the number after 'train'\n",
    "                train_directory = os.path.join(directory, d)\n",
    "                camera_pose[number],files = create_scale_dictionary(train_directory)  # Call to_be_done() with directory path\n",
    "                file_count+=files\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    \n",
    "    return camera_pose,file_count\n",
    "\n",
    "# Example usage\n",
    "directory_path = '/mnt/Velocity Vault/Personal/Projects/Python/Autofocus/Train'\n",
    "camera_pose,file_count = create_camera_pose_dict(directory_path)\n",
    "\n",
    "# Print the resulting dictionary\n",
    "print(\"Camera Pose Dictionary:\")\n",
    "\n",
    "# Print the dictionary\n",
    "import pprint\n",
    "pprint.pprint(camera_pose)\n",
    "\n",
    "print(f\"Number of .txt files processed: {file_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_path='/mnt/Velocity Vault/Personal/Projects/Python/Autofocus/Train/train2/'\n",
    "image_type='garage2_3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Directory path where images are stored\n",
    "path=super_path+'scaled_images/'+image_type\n",
    "\n",
    "# Filename pattern to filter\n",
    "filename_pattern = 'result_scaled_image_center.jpg'\n",
    "\n",
    "# Initialize an empty list to store images\n",
    "images = []\n",
    "\n",
    "# Recursively traverse the directory tree\n",
    "for root, _, files in os.walk(path):\n",
    "    for filename in files:\n",
    "        if filename == filename_pattern:\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(root, filename)\n",
    "            \n",
    "            # Open the image using PIL (assuming PNG format)\n",
    "            image = cv2.imread(file_path)\n",
    "            \n",
    "            #  the image to the list\n",
    "            images.append(image)\n",
    "\n",
    "# Now 'images' contains all images named 'result_up_pd_left_center.png' from the directory and its subfolders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have 49 images stored in a list called images\n",
    "# Each image in images should be a numpy array or a PIL Image object\n",
    "\n",
    "# Example list of 49 images (using placeholder numpy arrays)\n",
    "#images = [np.random.random((100, 100)) for _ in range(49)]\n",
    "\n",
    "# Determine layout of subplots (7x7 grid for 49 images)\n",
    "num_images = len(images)\n",
    "rows = 1\n",
    "cols = 7\n",
    "\n",
    "# Create figure and axis objects\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(30, 30))\n",
    "\n",
    "# Iterate over each image and plot it in corresponding axis\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < num_images:  # Plot only if there are images left\n",
    "        ax.imshow(images[i*7], cmap='gray')  # Assuming grayscale images\n",
    "        ax.axis('off')  # Turn off axis labels\n",
    "\n",
    "# Adjust layout to prevent overlap of subplots\n",
    "#plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def weighted_depth_map(depth_map, confidence_map, confidence_threshold=0.95):\n",
    "    # Flatten the depth map and confidence map\n",
    "    depth_values = depth_map.flatten()\n",
    "    confidence_values = confidence_map.flatten()\n",
    "    \n",
    "    # Filter out low confidence values if a threshold is provided\n",
    "    if confidence_threshold > 0.0:\n",
    "        mask = confidence_values >= confidence_threshold\n",
    "        depth_values = depth_values[mask]\n",
    "    \n",
    "    return depth_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import OpenEXR\n",
    "import Imath\n",
    "\n",
    "# Load the depth map (PNG file)\n",
    "depth_map_path=super_path+\"merged_depth/\"+image_type+'result_merged_depth_center.png'\n",
    "depth_map = cv2.imread(depth_map_path, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "\n",
    "# Load the depth map confidence (EXR file)\n",
    "depth_confidence_path=super_path+\"merged_conf/\"+image_type+'result_merged_conf_center.exr'\n",
    "\n",
    "def load_exr(file_path):\n",
    "    exr_file = OpenEXR.InputFile(file_path)\n",
    "    header = exr_file.header()\n",
    "    dw = header['dataWindow']\n",
    "    width = dw.max.x - dw.min.x + 1\n",
    "    height = dw.max.y - dw.min.y + 1\n",
    "    pt = Imath.PixelType(Imath.PixelType.FLOAT)\n",
    "    r = np.frombuffer(exr_file.channel('R', pt), dtype=np.float32)\n",
    "    r.shape = (height, width)\n",
    "    return r\n",
    "\n",
    "depth_map_confidence = load_exr(depth_confidence_path)\n",
    "\n",
    "# Define max and min values\n",
    "max_depth = 100.0\n",
    "min_depth = 0.2\n",
    "\n",
    "\n",
    "# Convert the depth map to meters using the given formula\n",
    "depth_values = weighted_depth_map(depth_map,depth_map_confidence)\n",
    "\n",
    "depth_map_in_meters = (max_depth * min_depth) / (max_depth - (max_depth - min_depth) * (depth_values / 255.0))\n",
    "\n",
    "# Compute the median value in the entire depth map\n",
    "median_depth = np.median(depth_map_in_meters)\n",
    "\n",
    "final_focus=median_depth*1000\n",
    "\n",
    "print(\"Median Depth in Mili Meters:\", median_depth*1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_focal_length=[3910.92,2289.27,1508.71,1185.83,935.91,801.09,700.37,605.39,546.23,486.87,447.99,407.40,379.91,350.41,329.95,307.54,291.72,274.13,261.53,247.35,237.08,225.41,216.88,207.10,198.18,191.60,183.96,178.29,171.69,165.57,160.99,155.61,150.59,146.81,142.35,138.98,134.99,131.23,127.69,124.99,121.77,118.73,116.40,113.63,110.99,108.47,106.54,104.23,102.01]\n",
    "\n",
    "def find_closest(value, num_list):\n",
    "    closest_value = min(num_list, key=lambda x: abs(x - value))\n",
    "    return closest_value\n",
    "\n",
    "closest_value = find_closest(final_focus, slice_focal_length)\n",
    "truth_slice=slice_focal_length.index(closest_value)\n",
    "print(\"Predicted Ground Truth Slice is\", truth_slice ,\"with\", closest_value,\"mm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import truth\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Parameters for border\n",
    "border_color = [255, 0, 0]  # Red color in RGB\n",
    "border_size = 5\n",
    "\n",
    "def add_border(image, border_size, border_color):\n",
    "    return cv2.copyMakeBorder(image, border_size, border_size, border_size, border_size, cv2.BORDER_CONSTANT, value=border_color)\n",
    "\n",
    "# Adding border to the xth image\n",
    "images[truth_slice] = add_border(images[truth_slice], border_size, border_color)\n",
    "\n",
    "# Create a figure with 7x7 subplots\n",
    "row_size=7 if truth_slice%7==0 else 8\n",
    "fig, axes = plt.subplots(1, row_size, figsize=(30, 30))\n",
    "\n",
    "truth_display=True\n",
    "# Plot each image\n",
    "i=0\n",
    "for ax in (axes.flat):\n",
    "    if (i*7)<49:\n",
    "        ax.imshow(images[i*7])\n",
    "    if i*7 > truth_slice and truth_slice>(i-1)*7 and truth_display:\n",
    "        ax.imshow(images[truth_slice])\n",
    "        i-=1\n",
    "        truth_display=False\n",
    "    ax.axis('off')  # Hide the axes\n",
    "    i+=1\n",
    "\n",
    "# Display the grid\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def generate_image_paths(super_path):\n",
    "    # Initialize the dictionary\n",
    "    image_path = {}\n",
    "\n",
    "    # Traverse the directory structure\n",
    "    for root, dirs, files in os.walk(super_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.png'):\n",
    "                # Get the relative path from super_path\n",
    "                relative_path = os.path.relpath(root, super_path)\n",
    "                # Split the relative path to get <string> and <integer>\n",
    "                string_part, integer_part = os.path.split(relative_path)\n",
    "                integer_part = int(integer_part)\n",
    "                \n",
    "                # Extract the position from the filename\n",
    "                file_name_parts = file.split('_')\n",
    "                position = file_name_parts[-1].split('.')[0]  # Extract 'bottom', 'top', etc.\n",
    "                \n",
    "                # Construct the full file path\n",
    "                full_file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Populate the dictionary\n",
    "                if string_part not in image_path:\n",
    "                    image_path[string_part] = {}\n",
    "                if integer_part not in image_path[string_part]:\n",
    "                    image_path[string_part][integer_part] = {}\n",
    "                \n",
    "                image_path[string_part][integer_part][position] = full_file_path\n",
    "\n",
    "    return image_path\n",
    "\n",
    "super_path = '/mnt/Velocity Vault/Personal/Projects/Python/Autofocus/Train/train1'\n",
    "\n",
    "left_image_path = generate_image_paths(super_path+'/raw_up_left_pd')\n",
    "right_image_path = generate_image_paths(super_path+'/raw_up_right_pd')\n",
    "import pprint\n",
    "pprint.pprint(left_image_path)\n",
    "pprint.pprint(right_image_path)\n",
    "\n",
    "def find_train_folders(directory):\n",
    "    train_folders = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for dir in dirs:\n",
    "            if dir.startswith('train'):\n",
    "                train_folders.append(os.path.join(root, dir))\n",
    "    return train_folders\n",
    "\n",
    "train_path=find_train_folders('/mnt/Velocity Vault/Personal/Projects/Python/Autofocus/Train/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "def collapse_last_dimension(arr):\n",
    "    # Ensure the array has the correct shape\n",
    "    assert arr.shape[-1] == 3, \"Input array must have shape AxBx3\"\n",
    "    \n",
    "    # Extract the first two dimensions (A and B)\n",
    "    collapsed_arr = arr[..., 0]\n",
    "    \n",
    "    return collapsed_arr\n",
    "\n",
    "image_path = '/mnt/Velocity Vault/Personal/Projects/Python/Autofocus/Train/train1/raw_up_left_pd/apt1_9/4/result_up_pd_left_center.png'\n",
    "image=cv2.imread(image_path)\n",
    "image=collapse_last_dimension(image)\n",
    "\n",
    "x=512\n",
    "y=512\n",
    "\n",
    "image=image[x:x+128,y:y+128]\n",
    "pprint.pprint(image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pprint\n",
    "# Load the image\n",
    "image_path = '/mnt/Velocity Vault/Personal/Projects/Python/Autofocus/Train/train1/raw_up_left_pd/apt1_9/4/result_up_pd_left_center.png'\n",
    "#image_path='/mnt/Velocity Vault/Personal/Projects/Python/Autofocus/Train/train1/merged_depth/apt1_1/result_merged_depth_bottom.png'\n",
    "image = cv2.imread(image_path)  # Use IMREAD_UNCHANGED to load alpha channel if it exists\n",
    "x=200\n",
    "y=1000\n",
    "image_patch=image[x:x+128,y:y+128]\n",
    "\n",
    "# Convert the image to a NumPy array\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Print the shape of the array to verify\n",
    "print(image_array.shape)\n",
    "#pprint.pprint(image_patch)\n",
    "\n",
    "# print(np.max(image_patch))\n",
    "# print(np.mean(image_patch))\n",
    "# print(np.min(image_patch))\n",
    "\n",
    "same =True\n",
    "for x in range(len(image_array)):\n",
    "    for y in range(len(image_array[x])):\n",
    "        a=image_array[x][y][0]\n",
    "        b=image_array[x][y][1]\n",
    "        c=image_array[x][y][2]\n",
    "\n",
    "        if(a!=b or b!=c or a!=c):\n",
    "            same=False\n",
    "            break\n",
    "print(same)\n",
    "\n",
    "\n",
    "def collapse_last_dimension(arr):\n",
    "    # Ensure the array has the correct shape\n",
    "    assert arr.shape[-1] == 3, \"Input array must have shape AxBx3\"\n",
    "    \n",
    "    # Extract the first two dimensions (A and B)\n",
    "    collapsed_arr = arr[..., 0]\n",
    "    \n",
    "    return collapsed_arr\n",
    "\n",
    "im=collapse_last_dimension(image_array)\n",
    "print(im.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def combine_arrays(arrays_list):\n",
    "\n",
    "    # Ensure all arrays in the list have the correct shape\n",
    "    assert all(arr.shape[-1] == 1 for arr in arrays_list), \"All arrays must have shape AxBx1\"\n",
    "    \n",
    "    # Determine the shape of the output array\n",
    "    A, B, _ = arrays_list[0].shape\n",
    "    s = len(arrays_list)\n",
    "    \n",
    "    # Initialize the combined array with lists in the last dimension\n",
    "    combined_array = np.empty((A, B, s), dtype=object)\n",
    "    \n",
    "    # Fill the combined array with lists from each input array\n",
    "    for i, arr in enumerate(arrays_list):\n",
    "        combined_array[..., i] = arr[..., 0].tolist()\n",
    "    \n",
    "    return combined_array\n",
    "\n",
    "# Example usage:\n",
    "# Create sample arrays of shape AxBx1\n",
    "array1 = np.array([[[1], [2]], [[3], [4]], [[5], [6]]])\n",
    "array2 = np.array([[[7], [8]], [[9], [10]], [[11], [12]]])\n",
    "\n",
    "# Combine the arrays\n",
    "combined_array = combine_arrays([array1, array2])\n",
    "\n",
    "print(\"Combined array:\")\n",
    "print(combined_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def collapse_last_dimension(arr):\n",
    "    # Ensure the array has the correct shape\n",
    "    assert arr.shape[-1] == 3, \"Input array must have shape AxBx3\"\n",
    "    \n",
    "    # Extract the first two dimensions (A and B)\n",
    "    collapsed_arr = arr[..., 0]\n",
    "    \n",
    "    return collapsed_arr\n",
    "\n",
    "# Example usage:\n",
    "# Create a sample numpy array of shape AxBx3\n",
    "arr = np.array([\n",
    "    [[1, 2, 3], [4, 5, 6]],\n",
    "    [[7, 8, 9], [10, 11, 12]],\n",
    "    [[13, 14, 15], [16, 17, 18]]\n",
    "])\n",
    "\n",
    "# Convert to AxB array\n",
    "collapsed_arr = collapse_last_dimension(arr)\n",
    "\n",
    "print(\"Original array:\")\n",
    "print(arr)\n",
    "print(\"\\nCollapsed array:\")\n",
    "print(collapsed_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def generate_random_patches(size=(504,378)):\n",
    "    image=np.zeros(size)\n",
    "    patches=[]\n",
    "    for _ in (range(100)):\n",
    "        x=random.randint(16, 487)\n",
    "        y=random.randint(16, 361)\n",
    "\n",
    "        #print(x,y)\n",
    "        \n",
    "        breaker=False\n",
    "\n",
    "        for i in range(x-26,x+26):\n",
    "            for j in range(y-26,y+26):\n",
    "                if i<0 or i>503 or j<0 or j>377 :\n",
    "                    continue\n",
    "                if image[i][j]==1:\n",
    "                    breaker=True\n",
    "                    break\n",
    "            if breaker:\n",
    "                break\n",
    "\n",
    "        if breaker:\n",
    "            continue\n",
    "        \n",
    "        x=x-16\n",
    "        y=y-16\n",
    "\n",
    "        for i in range(x,x+33):\n",
    "            for j in range(y,y+33):\n",
    "                image[i][j]=1\n",
    "\n",
    "        patches.append((x,y))\n",
    "\n",
    "    return patches\n",
    "\n",
    "patches=generate_random_patches()\n",
    "print(patches)\n",
    "print(\"Len :\",len(patches))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def plot_squares(size, coordinates):\n",
    "    # Create a figure and a set of subplots\n",
    "    fig, ax = plt.subplots(figsize=(size[0]/100, size[1]/100))  # figsize is in inches, so we divide by 100 to convert from pixels to inches\n",
    "    \n",
    "    # Iterate over each coordinate in the list\n",
    "    for x, y in coordinates:\n",
    "        # Create a rectangle patch\n",
    "        rect = patches.Rectangle((x, y), 32, 32, linewidth=1, edgecolor='black', facecolor='blue')\n",
    "        # Add the rectangle to the plot\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    # Set the limits of the plot to match the figure size\n",
    "    ax.set_xlim(0, size[0])\n",
    "    ax.set_ylim(0, size[1])\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis to match the typical coordinate system where (0,0) is at the top-left\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "coordinates = generate_random_patches()\n",
    "plot_squares((504, 378), coordinates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize x_train with zeros\n",
    "x_train = np.zeros((100, 98, 128, 128), dtype=np.int32)\n",
    "\n",
    "# Fill x_train with 1s in a progressive manner\n",
    "for i in range(98):\n",
    "    x_train[i, :, :, :] = i\n",
    "\n",
    "# Example to access and verify a slice of the array\n",
    "print(x_train.shape)  # Print the shape of x_train\n",
    "print(x_train[5, 23])  # Print the first 128x128 array in the first set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_to_list_array(arrays):\n",
    "    A = arrays[0].shape[0]  # Assuming all arrays have the same shape AxA\n",
    "    s = len(arrays)\n",
    "    \n",
    "    # Initialize the resulting array with lists\n",
    "    list_array = np.empty((A, A, s), dtype=object)\n",
    "    \n",
    "    # Fill the array with corresponding elements from each input array\n",
    "    for k, array in enumerate(arrays):\n",
    "        list_array[..., k] = array\n",
    "    \n",
    "    return list_array\n",
    "\n",
    "# Example usage:\n",
    "# Create sample numpy arrays\n",
    "arr1 = np.array([[1, 2], [3, 4]])\n",
    "arr2 = np.array([[5, 6], [7, 8]])\n",
    "arr3 = np.array([[9, 10], [11, 12]])\n",
    "\n",
    "# Convert to AxAxs array\n",
    "list_array = convert_to_list_array([arr1, arr2, arr3])\n",
    "\n",
    "print(\"Array 1:\")\n",
    "print(arr1)\n",
    "print(\"\\nArray 2:\")\n",
    "print(arr2)\n",
    "print(\"\\nArray 3:\")\n",
    "print(arr3)\n",
    "print(\"\\nConverted AxAxs array:\")\n",
    "print(list_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "# Step 1: Modify MobileNetV2 to accept 128x128x98 input\n",
    "def create_modified_mobilenetv2(input_shape=(128, 128, 98)):\n",
    "    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights=None)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # Assuming the output for the ordinal regression problem is a single value\n",
    "    outputs = Dense(1)(x)\n",
    "    model = Model(inputs=base_model.input, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Step 2: Implement the ordinal regression loss\n",
    "def ordinal_regression_loss(y_true, y_pred):\n",
    "    # L2 loss (mean squared error)\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Step 3: Set up the training loop\n",
    "def train_model(model, train_dataset, steps_per_epoch=20000, batch_size=128, initial_lr=1e-3, beta1=0.5, beta2=0.999):\n",
    "    optimizer = Adam(learning_rate=initial_lr, beta_1=beta1, beta_2=beta2)\n",
    "    model.compile(optimizer=optimizer, loss=ordinal_regression_loss)\n",
    "    \n",
    "    model.fit(train_dataset, epochs=int(steps_per_epoch // (len(train_dataset) / batch_size)), steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "# Create the model\n",
    "input_shape = (128, 128, 98)\n",
    "model = create_modified_mobilenetv2(input_shape=input_shape)\n",
    "\n",
    "batch_size=500\n",
    "# Initialize x_train with zeros\n",
    "x_train = np.zeros((batch_size, 128, 128,98), dtype=np.int32)\n",
    "\n",
    "# Fill x_train with 1s in a progressive manner\n",
    "for i in range(batch_size):\n",
    "    x_train[i, :, :, :] = i\n",
    "\n",
    "y_train = [i+1 for i in range(batch_size)]\n",
    "\n",
    "# Assume train_dataset is a TensorFlow Dataset object containing your training data\n",
    "# For example:\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size).shuffle(buffer_size=43121)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_dataset, steps_per_epoch=2, batch_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# Custom Input Layer\n",
    "input_shape = (128, 128, 98)\n",
    "base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights=None)\n",
    "\n",
    "# Global Average Pooling Layer\n",
    "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "\n",
    "# Fully Connected Layer\n",
    "x = layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "# Create the model\n",
    "model = models.Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Custom Ordinal Regression Loss Function\n",
    "def ordinal_regression_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Compile the model with the specified optimizer and loss function\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, beta_1=0.5, beta_2=0.999),\n",
    "              loss=ordinal_regression_loss)\n",
    "\n",
    "# Sample training data (replace with actual data)\n",
    "import numpy as np\n",
    "\n",
    "# Dummy data for illustration; replace with your actual data loading code\n",
    "num_samples = 800\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Initialize x_train with zeros\n",
    "x_train = np.zeros((num_samples, 128, 128,98), dtype=np.int32)\n",
    "\n",
    "# Fill x_train with 1s in a progressive manner\n",
    "for i in range(num_samples):\n",
    "    x_train[i, :, :, :] = i\n",
    "\n",
    "y_train = [i+1 for i in range(num_samples)]\n",
    "\n",
    "# Create dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(10)\n",
    "\n",
    "# Train the model\n",
    "model.fit(dataset, epochs=5, steps_per_epoch=10 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples=125\n",
    "\n",
    "x_test=np.zeros((num_samples, 128, 128,98), dtype=np.int32)\n",
    "\n",
    "for i in range(num_samples):\n",
    "    x_test[i, :, :, :] = i\n",
    "\n",
    "y_test = [i+1 for i in range(num_samples)]\n",
    "\n",
    "loss=model.evaluate(np.array(x_test),np.array(y_test))\n",
    "print('Test loss =',loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import random\n",
    "import numpy as np\n",
    "print(\"hell\")\n",
    "\n",
    "x_train = np.random.randint(low=0, high=256, size=(1915,128,128,98), dtype=np.int32)\n",
    "print(\"hell\")\n",
    "y_train = np.random.randint(low=0, high=256, size=(1915), dtype=np.int32)\n",
    "print(\"hell\")\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32).shuffle(buffer_size=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
      "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def save_list_to_file(dataset, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(dataset, file)\n",
    "\n",
    "def load_list_from_file(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "name='/mnt/Velocity Vault/Personal/Projects/Python/Autofocus/dataset_cache.pkl'\n",
    "# Example usage:\n",
    "my_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "save_list_to_file(my_list, name)\n",
    "\n",
    "loaded_list = load_list_from_file(name)\n",
    "print(my_list)\n",
    "print(loaded_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to cache.pkl\n",
      "Array reshaped to (2, 128, 128, 98)\n",
      "array([[[[130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         ...,\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130]],\n",
      "\n",
      "        [[130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         ...,\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130]],\n",
      "\n",
      "        [[130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         ...,\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         ...,\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130]],\n",
      "\n",
      "        [[130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         ...,\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130]],\n",
      "\n",
      "        [[130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         ...,\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130]]],\n",
      "\n",
      "\n",
      "       [[[130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         ...,\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130]],\n",
      "\n",
      "        [[130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         ...,\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130]],\n",
      "\n",
      "        [[130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         ...,\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         ...,\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130]],\n",
      "\n",
      "        [[130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         ...,\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130]],\n",
      "\n",
      "        [[130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         ...,\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130],\n",
      "         [130, 130, 130, ..., 130, 130, 130]]]], dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate a random list with integers (0 to 255) in the shape 1921x128x128x98\n",
    "shape = ( 2,128, 128, 98)\n",
    "random_array = np.full(shape, 130, dtype=np.uint8)\n",
    "# Flatten the array\n",
    "flattened_array = random_array.flatten()\n",
    "\n",
    "# Write the flattened array to a text file separated by commas\n",
    "def write_dataset_to_file(dataset,filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(','.join(map(str, dataset)))\n",
    "\n",
    "    print(f\"Data written to {filename}\")\n",
    "    \n",
    "filename = 'cache.txt'\n",
    "write_dataset_to_file(flattened_array,filename)\n",
    "\n",
    "# Code to read the file and reshape the array back to its original shape\n",
    "def read_and_reshape(filename, shape):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = file.read().split(',')\n",
    "    array = np.array(data, dtype=np.uint8)\n",
    "    reshaped_array = array.reshape(shape)\n",
    "    return reshaped_array\n",
    "\n",
    "# Example of reading and reshaping the array\n",
    "reshaped_array = read_and_reshape(filename, shape)\n",
    "print(f\"Array reshaped to {reshaped_array.shape}\")\n",
    "import pprint\n",
    "pprint.pprint(reshaped_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 72.05859375 MB\n"
     ]
    }
   ],
   "source": [
    "from memory_profiler import memory_usage\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "def measure_memory_usage(func, *args, **kwargs):\n",
    "    result = None\n",
    "    def wrapper():\n",
    "        nonlocal result\n",
    "        result = func(*args, **kwargs)\n",
    "        return result\n",
    "    \n",
    "    mem_usage = memory_usage(wrapper, interval=0.1)\n",
    "    \n",
    "    return result, max(mem_usage) - min(mem_usage)\n",
    "\n",
    "# Example usage\n",
    "def example_function(data):\n",
    "    # Some operation on data\n",
    "    data = data * 2\n",
    "    return data\n",
    "\n",
    "data = np.random.rand(10000, 1000)\n",
    "\n",
    "result, mem_usage = measure_memory_usage(example_function, data)\n",
    "print(f\"Memory usage: {mem_usage} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [06:04<00:00, 274.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to /mnt/Velocity Vault/Personal/Projects/Python/Autofocus/data.txt in 100000 parts\n",
      "Memory usage: (None, 6515.59765625) MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def save_list_to_file(data, filename, partitions):\n",
    "    data = data.flatten()\n",
    "    partition_size = len(data) // partitions\n",
    "\n",
    "    with open(filename, 'w') as file:\n",
    "        for i in tqdm(range(partitions)):\n",
    "            start_idx = i * partition_size\n",
    "            if i == partitions - 1:  # last partition\n",
    "                partition_data = data[start_idx:]\n",
    "            else:\n",
    "                end_idx = start_idx + partition_size\n",
    "                partition_data = data[start_idx:end_idx]\n",
    "            \n",
    "            file.write('\\n'.join(map(str, partition_data)))\n",
    "            if i != partitions - 1:\n",
    "                file.write('\\n')\n",
    "\n",
    "    print(f\"Data written to {filename} in {partitions} parts\")\n",
    "    \n",
    "\n",
    "shape=(2000,128,128,98)\n",
    "# Example usage\n",
    "data = np.random.randint(0, 256, size=shape, dtype=np.uint8)\n",
    "mem_usage=measure_memory_usage(save_list_to_file,data, '/mnt/Velocity Vault/Personal/Projects/Python/Autofocus/data.txt', partitions=100000)\n",
    "print(f\"Memory usage: {mem_usage} MB\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 27095295/3211264000 [00:07<15:00, 3534063.55it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m     array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mreshape(shape)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m array\n\u001b[0;32m---> 27\u001b[0m loaded,mem_usage\u001b[38;5;241m=\u001b[39m\u001b[43mmeasure_memory_usage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_list_from_file\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/mnt/Velocity Vault/Personal/Projects/Python/Autofocus/data.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMemory usage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmem_usage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m, in \u001b[0;36mmeasure_memory_usage\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m---> 12\u001b[0m mem_usage \u001b[38;5;241m=\u001b[39m \u001b[43mmemory_usage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result, \u001b[38;5;28mmax\u001b[39m(mem_usage) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmin\u001b[39m(mem_usage)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/memory_profiler.py:379\u001b[0m, in \u001b[0;36mmemory_usage\u001b[0;34m(proc, interval, timeout, timestamps, include_children, multiprocess, max_usage, retval, stream, backend, max_iterations)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# When there is an exception in the \"proc\" - the (spawned) monitoring processes don't get killed.\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# Therefore, the whole process hangs indefinitely. Here, we are ensuring that the process gets killed!\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     returned \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     parent_conn\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# finish timing\u001b[39;00m\n\u001b[1;32m    381\u001b[0m     ret \u001b[38;5;241m=\u001b[39m parent_conn\u001b[38;5;241m.\u001b[39mrecv()\n",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m, in \u001b[0;36mmeasure_memory_usage.<locals>.wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m():\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m result\n\u001b[0;32m----> 9\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m, in \u001b[0;36mload_list_from_file\u001b[0;34m(filename, shape, partition_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m line \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreadline()\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m line:\n\u001b[0;32m---> 14\u001b[0m     chunk\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m     index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     16\u001b[0m     pgbr\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 27380533/3211264000 [00:23<15:00, 3534063.55it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_list_from_file(filename, shape, partition_size):\n",
    "    # Calculate the total number of elements needed\n",
    "    total_elements = np.prod(shape)\n",
    "    array = np.empty(total_elements, dtype=np.uint8)\n",
    "    pgbr=tqdm(total=total_elements)\n",
    "    # Open the file and read in chunks\n",
    "    with open(filename, 'r') as file:\n",
    "        index = 0\n",
    "        while index < total_elements:\n",
    "            chunk = []\n",
    "            while len(chunk) < partition_size and index < total_elements:\n",
    "                line = file.readline().strip()\n",
    "                if line:\n",
    "                    chunk.append(int(line))\n",
    "                    index += 1\n",
    "                    pgbr.update(1)\n",
    "\n",
    "            if chunk:\n",
    "                array[index - len(chunk):index] = np.array(chunk, dtype=np.uint8)\n",
    "    \n",
    "    pgbr.close()\n",
    "\n",
    "    # Reshape the array to the desired shape\n",
    "    array = array.reshape(shape)\n",
    "    return array\n",
    "\n",
    "loaded,mem_usage=measure_memory_usage(load_list_from_file,'/mnt/Velocity Vault/Personal/Projects/Python/Autofocus/data.txt',shape,100000)\n",
    "print(f\"Memory usage: {mem_usage} MB\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[[ 16,  74, 167, ..., 223,  59, 240],\n",
      "         [161, 226,  96, ..., 168, 105,  57],\n",
      "         [119, 224,  38, ..., 178, 130,  64],\n",
      "         ...,\n",
      "         [222, 252, 235, ..., 177, 187, 247],\n",
      "         [227, 236,  18, ..., 246, 159, 139],\n",
      "         [161, 134,  48, ..., 135,   3, 138]],\n",
      "\n",
      "        [[134, 226, 158, ..., 246,  54, 250],\n",
      "         [200, 107,  88, ..., 228, 177, 245],\n",
      "         [ 86, 220, 220, ...,  13,  23, 184],\n",
      "         ...,\n",
      "         [ 23,  74, 246, ..., 146, 183, 212],\n",
      "         [ 93,  66,  80, ...,  94,  52, 135],\n",
      "         [150, 242,  56, ...,  70, 162,  82]],\n",
      "\n",
      "        [[198,  27, 112, ...,  86, 164, 255],\n",
      "         [ 91, 177, 146, ..., 222, 155,  51],\n",
      "         [105,  58,  73, ..., 230,  13,  81],\n",
      "         ...,\n",
      "         [158,  61, 143, ..., 122, 120, 183],\n",
      "         [252, 114, 197, ..., 168,  18, 114],\n",
      "         [111,  81,  84, ..., 165, 158, 240]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 54, 202, 241, ..., 156,   0, 226],\n",
      "         [195, 206,  87, ..., 165, 188,  89],\n",
      "         [158, 111, 191, ...,  93, 204,  29],\n",
      "         ...,\n",
      "         [164, 106, 237, ...,  24, 134, 140],\n",
      "         [209,  71, 113, ...,  93, 100, 117],\n",
      "         [194, 248, 204, ...,  80, 216,   5]],\n",
      "\n",
      "        [[218, 252, 139, ..., 113,  36, 247],\n",
      "         [143, 102,  10, ..., 213,  18,  98],\n",
      "         [235,  62, 183, ...,  32, 123, 146],\n",
      "         ...,\n",
      "         [110, 230, 137, ..., 249,  58,   3],\n",
      "         [240,  59, 159, ...,  39,   0, 164],\n",
      "         [243, 140, 222, ..., 110,  28, 177]],\n",
      "\n",
      "        [[236, 234,  83, ..., 226, 226, 216],\n",
      "         [110,  86, 232, ..., 157, 163, 211],\n",
      "         [153,  13, 135, ...,  17, 172, 184],\n",
      "         ...,\n",
      "         [ 41,  66,  63, ..., 110,  52, 192],\n",
      "         [225,  89, 206, ..., 204,  88,  72],\n",
      "         [  3,  55,  15, ..., 221,  70, 228]]],\n",
      "\n",
      "\n",
      "       [[[131, 125,  11, ..., 179, 192, 136],\n",
      "         [235, 164, 223, ..., 106,  62,  49],\n",
      "         [ 86,   7, 151, ..., 107,  21, 196],\n",
      "         ...,\n",
      "         [154,  79,   6, ...,  70,  80, 170],\n",
      "         [ 34, 151,  77, ..., 139, 251, 220],\n",
      "         [153,  60,  36, ...,  10,  50,  22]],\n",
      "\n",
      "        [[109,  93,  14, ...,  57, 185,  83],\n",
      "         [200, 229,  16, ..., 112,  72, 127],\n",
      "         [130, 198, 253, ..., 243, 255,  38],\n",
      "         ...,\n",
      "         [126,   9, 210, ..., 190, 240, 111],\n",
      "         [ 19, 172, 125, ..., 234,   5, 250],\n",
      "         [254, 123, 117, ...,  30, 228, 116]],\n",
      "\n",
      "        [[ 71,  17,  61, ...,  35, 124,  85],\n",
      "         [176,  43,  65, ...,  37,   8, 212],\n",
      "         [ 15, 254,  54, ..., 137, 188, 117],\n",
      "         ...,\n",
      "         [247, 208, 208, ..., 157, 103,  46],\n",
      "         [ 29, 179, 104, ..., 165,  64, 141],\n",
      "         [129,  76, 123, ...,  84,  23, 166]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[219, 105, 122, ..., 208,  59,  61],\n",
      "         [210, 143, 118, ..., 102, 236, 203],\n",
      "         [ 47,  67,  20, ..., 138, 146, 161],\n",
      "         ...,\n",
      "         [134,  33, 119, ..., 254, 209, 239],\n",
      "         [101, 211, 181, ..., 218,   7, 178],\n",
      "         [199, 154, 214, ..., 254,  78,  69]],\n",
      "\n",
      "        [[139,   6, 241, ...,  19, 101, 166],\n",
      "         [204, 108, 228, ..., 128, 105,  94],\n",
      "         [209, 174, 138, ..., 195, 160, 103],\n",
      "         ...,\n",
      "         [ 60, 247, 186, ..., 255, 137, 197],\n",
      "         [228, 252,  74, ...,  95, 158, 139],\n",
      "         [166, 137,  11, ...,  40, 146, 242]],\n",
      "\n",
      "        [[139, 163,  28, ..., 150, 182, 202],\n",
      "         [184,   0,  64, ..., 164,  90, 193],\n",
      "         [236, 247, 183, ..., 101, 118, 114],\n",
      "         ...,\n",
      "         [201,  12,  43, ...,  11,  26,  57],\n",
      "         [125, 227, 183, ..., 205, 135, 187],\n",
      "         [168, 104,  76, ...,  58, 254, 118]]],\n",
      "\n",
      "\n",
      "       [[[238, 151,  61, ...,   1, 220, 170],\n",
      "         [240, 242,   9, ..., 106,  97,  72],\n",
      "         [107, 243, 250, ...,  87, 113, 242],\n",
      "         ...,\n",
      "         [226,  55, 163, ...,  55, 153, 226],\n",
      "         [124, 127, 176, ..., 193,  72, 130],\n",
      "         [239, 106,  39, ..., 188,  50,  35]],\n",
      "\n",
      "        [[ 55, 133,  85, ...,  30, 245,  53],\n",
      "         [ 18, 253, 174, ..., 138,  26, 163],\n",
      "         [  9, 254, 211, ..., 182, 216, 208],\n",
      "         ...,\n",
      "         [ 33,  48, 184, ...,  88,  91,  10],\n",
      "         [117, 220,  25, ...,   6, 166, 211],\n",
      "         [155,   3,  66, ...,  56, 237, 252]],\n",
      "\n",
      "        [[222,  20, 211, ...,  18,  86, 141],\n",
      "         [150, 157, 205, ...,  13,  28, 221],\n",
      "         [ 21,  72, 118, ..., 244,  74,  56],\n",
      "         ...,\n",
      "         [ 97, 255, 209, ..., 112, 240, 156],\n",
      "         [229, 241, 147, ...,  56,  82, 114],\n",
      "         [253,   4,  78, ...,  44, 246, 128]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 16,  84,  87, ...,  47, 109, 118],\n",
      "         [104, 136, 187, ...,  51, 141,  37],\n",
      "         [ 70,  68,  83, ..., 240,   9,  83],\n",
      "         ...,\n",
      "         [ 79,  77,  96, ...,  18,  68, 114],\n",
      "         [115, 114, 158, ...,  65, 175, 102],\n",
      "         [192,  19, 154, ..., 104, 176,  77]],\n",
      "\n",
      "        [[215, 154,  40, ..., 167,  23, 119],\n",
      "         [ 48,  33, 179, ..., 116,  15,  37],\n",
      "         [241,  69,  78, ..., 195,  82, 233],\n",
      "         ...,\n",
      "         [  2, 242,  64, ..., 245,  21, 124],\n",
      "         [171,  50, 126, ...,  67,  10, 181],\n",
      "         [169,  14, 172, ..., 240,  19,  27]],\n",
      "\n",
      "        [[  7, 155,  70, ..., 127,  36, 167],\n",
      "         [151, 108, 135, ..., 254, 131, 107],\n",
      "         [191, 209, 248, ...,  59, 211,   3],\n",
      "         ...,\n",
      "         [ 70,  84, 121, ...,   8, 100,  49],\n",
      "         [226, 163, 190, ..., 250,  57, 146],\n",
      "         [189, 229, 185, ...,  42, 144, 234]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[254, 231, 148, ..., 223, 196, 159],\n",
      "         [ 70,  56, 236, ..., 235, 131, 239],\n",
      "         [154,  75,  18, ..., 203,  73,  25],\n",
      "         ...,\n",
      "         [199, 162, 133, ...,  95,  64, 236],\n",
      "         [186, 207, 147, ...,  25,   4, 102],\n",
      "         [143, 123, 224, ..., 233, 152, 222]],\n",
      "\n",
      "        [[226,  30, 151, ..., 185,  44, 246],\n",
      "         [129,  38,  94, ..., 251,  54,  10],\n",
      "         [244, 250,  16, ..., 107,  59, 175],\n",
      "         ...,\n",
      "         [  0, 243,  20, ..., 169, 147, 192],\n",
      "         [109, 216,  59, ...,  22,  48, 239],\n",
      "         [ 72, 148, 103, ..., 118, 118, 211]],\n",
      "\n",
      "        [[ 99, 191,  47, ..., 181, 214,  92],\n",
      "         [199, 202, 161, ..., 128, 212, 136],\n",
      "         [139,  26, 162, ...,  10, 245, 204],\n",
      "         ...,\n",
      "         [ 24,  30,  77, ..., 245,  65, 219],\n",
      "         [ 76, 137, 176, ...,  64, 188, 162],\n",
      "         [254, 182, 174, ...,  11,  58, 173]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 85, 144,  49, ...,  50, 203, 100],\n",
      "         [ 31, 227, 248, ...,  28,   8, 119],\n",
      "         [100, 179, 144, ...,  42, 235,  47],\n",
      "         ...,\n",
      "         [126, 224, 163, ..., 104, 161, 201],\n",
      "         [196,  55, 101, ...,  73,  13, 131],\n",
      "         [220, 152,  13, ...,  41, 218,  86]],\n",
      "\n",
      "        [[ 40,  94, 193, ..., 113, 221, 139],\n",
      "         [119,  67, 254, ..., 198, 134, 235],\n",
      "         [124,  57, 134, ...,   1, 216,  70],\n",
      "         ...,\n",
      "         [ 74, 205,   0, ...,  12, 244,  81],\n",
      "         [167,  56,  68, ..., 135, 110, 230],\n",
      "         [ 61, 238,  84, ..., 117, 144, 116]],\n",
      "\n",
      "        [[252, 147, 139, ..., 223, 123,   9],\n",
      "         [241, 146, 149, ..., 114,  38,   9],\n",
      "         [168, 213, 255, ...,  67,  92,  47],\n",
      "         ...,\n",
      "         [236,  14, 213, ..., 130,  45,  47],\n",
      "         [179,  86, 117, ...,   5, 226, 216],\n",
      "         [214, 215, 187, ..., 203, 250, 126]]],\n",
      "\n",
      "\n",
      "       [[[192, 207,  90, ...,  20, 172, 217],\n",
      "         [243, 129,   8, ..., 145, 159,  88],\n",
      "         [ 50, 168, 233, ..., 217, 220,  27],\n",
      "         ...,\n",
      "         [230, 233,  14, ..., 211, 142, 167],\n",
      "         [152,  67, 127, ..., 244, 226,  43],\n",
      "         [108, 182,  84, ..., 143,  43, 133]],\n",
      "\n",
      "        [[182, 155,  12, ..., 169,  22, 232],\n",
      "         [254, 206, 192, ...,  11,  70, 212],\n",
      "         [173, 139, 134, ...,  97,  86, 100],\n",
      "         ...,\n",
      "         [161, 183, 127, ..., 110, 162, 236],\n",
      "         [158,  47,  75, ..., 158, 123, 244],\n",
      "         [171, 227, 142, ..., 223,  18, 170]],\n",
      "\n",
      "        [[201, 238,  11, ...,  80, 120,  37],\n",
      "         [122, 116, 227, ..., 139, 212, 146],\n",
      "         [163, 164, 220, ...,  11,   2,  17],\n",
      "         ...,\n",
      "         [190,  15,  39, ..., 153,   1,  99],\n",
      "         [ 79, 186, 129, ..., 241, 180, 152],\n",
      "         [124,  74, 139, ...,  62, 191,  29]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[251,  78,  36, ..., 240, 134,  18],\n",
      "         [  6, 219, 177, ..., 203, 173, 151],\n",
      "         [179,  97, 178, ..., 223,  13, 209],\n",
      "         ...,\n",
      "         [ 41,  67, 237, ..., 132,  29, 186],\n",
      "         [242, 198,  14, ..., 178, 124, 114],\n",
      "         [105, 116,  90, ..., 160, 167, 236]],\n",
      "\n",
      "        [[176,  93, 213, ..., 213,  98,  95],\n",
      "         [247,  57,  33, ..., 112, 103, 211],\n",
      "         [223, 184, 169, ..., 225, 235,  81],\n",
      "         ...,\n",
      "         [122,  60, 162, ...,  25, 161,  99],\n",
      "         [ 87,  29, 200, ..., 247,  43, 145],\n",
      "         [ 24, 217, 141, ..., 150, 116,  64]],\n",
      "\n",
      "        [[196,  64,  59, ..., 165, 237,  91],\n",
      "         [ 85, 133, 134, ..., 133,  36, 168],\n",
      "         [  8, 239,  29, ..., 210, 105,   0],\n",
      "         ...,\n",
      "         [112, 214,  35, ..., 242,  37, 206],\n",
      "         [140,  71,  59, ...,  59, 168, 112],\n",
      "         [ 64,  17, 196, ...,  99,  32, 219]]],\n",
      "\n",
      "\n",
      "       [[[ 71,  67, 214, ..., 175,  99, 231],\n",
      "         [ 52, 174,  62, ..., 131, 180, 154],\n",
      "         [100,  81, 186, ..., 179, 196, 181],\n",
      "         ...,\n",
      "         [ 47, 224, 217, ...,  87,  54, 151],\n",
      "         [229, 192, 145, ..., 155, 246, 111],\n",
      "         [  9, 225, 232, ..., 255,  53, 140]],\n",
      "\n",
      "        [[111, 100, 146, ..., 225, 161, 191],\n",
      "         [ 49, 188,  84, ..., 253, 206, 137],\n",
      "         [234,  86,  99, ..., 243, 213, 161],\n",
      "         ...,\n",
      "         [ 27,   3, 136, ...,  92, 153,  76],\n",
      "         [247,  56,  77, ...,  31,  34,  36],\n",
      "         [234, 159, 138, ..., 223, 127, 138]],\n",
      "\n",
      "        [[ 88, 234,   0, ...,  60, 113, 124],\n",
      "         [ 21,  37,  19, ...,   1,  29,  83],\n",
      "         [150,  76,  54, ...,  68, 205,  63],\n",
      "         ...,\n",
      "         [ 53, 138,  35, ..., 169,  87,  49],\n",
      "         [ 27, 224,  43, ..., 132,  46,  84],\n",
      "         [ 82,  91, 178, ..., 210,  79, 168]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 86,  15,  55, ...,  48, 229,  79],\n",
      "         [ 32,  42, 156, ..., 152, 203, 196],\n",
      "         [183, 210, 209, ..., 133,  94, 173],\n",
      "         ...,\n",
      "         [228, 113, 136, ...,  33, 184,  35],\n",
      "         [112, 244,  27, ...,  52, 205, 164],\n",
      "         [173, 249, 227, ...,  96, 127,  26]],\n",
      "\n",
      "        [[149,  30,   0, ..., 192,  65, 107],\n",
      "         [ 62, 160,  25, ..., 239, 255, 143],\n",
      "         [ 19, 198, 101, ..., 193, 227,  61],\n",
      "         ...,\n",
      "         [ 51, 213,  42, ...,  66, 122,  58],\n",
      "         [ 21, 184, 250, ...,  83,  77,  90],\n",
      "         [ 22,  99,  64, ...,  67, 109, 193]],\n",
      "\n",
      "        [[ 24, 111,  63, ..., 150,  70, 122],\n",
      "         [209,  64, 125, ...,  75, 225, 180],\n",
      "         [165,  63,  96, ...,  53, 180,  40],\n",
      "         ...,\n",
      "         [ 37,  54,  56, ...,  33, 254, 150],\n",
      "         [167,  14, 244, ...,  81, 206,  68],\n",
      "         [126, 183, 136, ..., 200, 216, 143]]]], dtype=uint8)\n",
      "array([[[[ 16,  74, 167, ..., 223,  59, 240],\n",
      "         [161, 226,  96, ..., 168, 105,  57],\n",
      "         [119, 224,  38, ..., 178, 130,  64],\n",
      "         ...,\n",
      "         [222, 252, 235, ..., 177, 187, 247],\n",
      "         [227, 236,  18, ..., 246, 159, 139],\n",
      "         [161, 134,  48, ..., 135,   3, 138]],\n",
      "\n",
      "        [[134, 226, 158, ..., 246,  54, 250],\n",
      "         [200, 107,  88, ..., 228, 177, 245],\n",
      "         [ 86, 220, 220, ...,  13,  23, 184],\n",
      "         ...,\n",
      "         [ 23,  74, 246, ..., 146, 183, 212],\n",
      "         [ 93,  66,  80, ...,  94,  52, 135],\n",
      "         [150, 242,  56, ...,  70, 162,  82]],\n",
      "\n",
      "        [[198,  27, 112, ...,  86, 164, 255],\n",
      "         [ 91, 177, 146, ..., 222, 155,  51],\n",
      "         [105,  58,  73, ..., 230,  13,  81],\n",
      "         ...,\n",
      "         [158,  61, 143, ..., 122, 120, 183],\n",
      "         [252, 114, 197, ..., 168,  18, 114],\n",
      "         [111,  81,  84, ..., 165, 158, 240]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 54, 202, 241, ..., 156,   0, 226],\n",
      "         [195, 206,  87, ..., 165, 188,  89],\n",
      "         [158, 111, 191, ...,  93, 204,  29],\n",
      "         ...,\n",
      "         [164, 106, 237, ...,  24, 134, 140],\n",
      "         [209,  71, 113, ...,  93, 100, 117],\n",
      "         [194, 248, 204, ...,  80, 216,   5]],\n",
      "\n",
      "        [[218, 252, 139, ..., 113,  36, 247],\n",
      "         [143, 102,  10, ..., 213,  18,  98],\n",
      "         [235,  62, 183, ...,  32, 123, 146],\n",
      "         ...,\n",
      "         [110, 230, 137, ..., 249,  58,   3],\n",
      "         [240,  59, 159, ...,  39,   0, 164],\n",
      "         [243, 140, 222, ..., 110,  28, 177]],\n",
      "\n",
      "        [[236, 234,  83, ..., 226, 226, 216],\n",
      "         [110,  86, 232, ..., 157, 163, 211],\n",
      "         [153,  13, 135, ...,  17, 172, 184],\n",
      "         ...,\n",
      "         [ 41,  66,  63, ..., 110,  52, 192],\n",
      "         [225,  89, 206, ..., 204,  88,  72],\n",
      "         [  3,  55,  15, ..., 221,  70, 228]]],\n",
      "\n",
      "\n",
      "       [[[131, 125,  11, ..., 179, 192, 136],\n",
      "         [235, 164, 223, ..., 106,  62,  49],\n",
      "         [ 86,   7, 151, ..., 107,  21, 196],\n",
      "         ...,\n",
      "         [154,  79,   6, ...,  70,  80, 170],\n",
      "         [ 34, 151,  77, ..., 139, 251, 220],\n",
      "         [153,  60,  36, ...,  10,  50,  22]],\n",
      "\n",
      "        [[109,  93,  14, ...,  57, 185,  83],\n",
      "         [200, 229,  16, ..., 112,  72, 127],\n",
      "         [130, 198, 253, ..., 243, 255,  38],\n",
      "         ...,\n",
      "         [126,   9, 210, ..., 190, 240, 111],\n",
      "         [ 19, 172, 125, ..., 234,   5, 250],\n",
      "         [254, 123, 117, ...,  30, 228, 116]],\n",
      "\n",
      "        [[ 71,  17,  61, ...,  35, 124,  85],\n",
      "         [176,  43,  65, ...,  37,   8, 212],\n",
      "         [ 15, 254,  54, ..., 137, 188, 117],\n",
      "         ...,\n",
      "         [247, 208, 208, ..., 157, 103,  46],\n",
      "         [ 29, 179, 104, ..., 165,  64, 141],\n",
      "         [129,  76, 123, ...,  84,  23, 166]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[219, 105, 122, ..., 208,  59,  61],\n",
      "         [210, 143, 118, ..., 102, 236, 203],\n",
      "         [ 47,  67,  20, ..., 138, 146, 161],\n",
      "         ...,\n",
      "         [134,  33, 119, ..., 254, 209, 239],\n",
      "         [101, 211, 181, ..., 218,   7, 178],\n",
      "         [199, 154, 214, ..., 254,  78,  69]],\n",
      "\n",
      "        [[139,   6, 241, ...,  19, 101, 166],\n",
      "         [204, 108, 228, ..., 128, 105,  94],\n",
      "         [209, 174, 138, ..., 195, 160, 103],\n",
      "         ...,\n",
      "         [ 60, 247, 186, ..., 255, 137, 197],\n",
      "         [228, 252,  74, ...,  95, 158, 139],\n",
      "         [166, 137,  11, ...,  40, 146, 242]],\n",
      "\n",
      "        [[139, 163,  28, ..., 150, 182, 202],\n",
      "         [184,   0,  64, ..., 164,  90, 193],\n",
      "         [236, 247, 183, ..., 101, 118, 114],\n",
      "         ...,\n",
      "         [201,  12,  43, ...,  11,  26,  57],\n",
      "         [125, 227, 183, ..., 205, 135, 187],\n",
      "         [168, 104,  76, ...,  58, 254, 118]]],\n",
      "\n",
      "\n",
      "       [[[238, 151,  61, ...,   1, 220, 170],\n",
      "         [240, 242,   9, ..., 106,  97,  72],\n",
      "         [107, 243, 250, ...,  87, 113, 242],\n",
      "         ...,\n",
      "         [226,  55, 163, ...,  55, 153, 226],\n",
      "         [124, 127, 176, ..., 193,  72, 130],\n",
      "         [239, 106,  39, ..., 188,  50,  35]],\n",
      "\n",
      "        [[ 55, 133,  85, ...,  30, 245,  53],\n",
      "         [ 18, 253, 174, ..., 138,  26, 163],\n",
      "         [  9, 254, 211, ..., 182, 216, 208],\n",
      "         ...,\n",
      "         [ 33,  48, 184, ...,  88,  91,  10],\n",
      "         [117, 220,  25, ...,   6, 166, 211],\n",
      "         [155,   3,  66, ...,  56, 237, 252]],\n",
      "\n",
      "        [[222,  20, 211, ...,  18,  86, 141],\n",
      "         [150, 157, 205, ...,  13,  28, 221],\n",
      "         [ 21,  72, 118, ..., 244,  74,  56],\n",
      "         ...,\n",
      "         [ 97, 255, 209, ..., 112, 240, 156],\n",
      "         [229, 241, 147, ...,  56,  82, 114],\n",
      "         [253,   4,  78, ...,  44, 246, 128]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 16,  84,  87, ...,  47, 109, 118],\n",
      "         [104, 136, 187, ...,  51, 141,  37],\n",
      "         [ 70,  68,  83, ..., 240,   9,  83],\n",
      "         ...,\n",
      "         [ 79,  77,  96, ...,  18,  68, 114],\n",
      "         [115, 114, 158, ...,  65, 175, 102],\n",
      "         [192,  19, 154, ..., 104, 176,  77]],\n",
      "\n",
      "        [[215, 154,  40, ..., 167,  23, 119],\n",
      "         [ 48,  33, 179, ..., 116,  15,  37],\n",
      "         [241,  69,  78, ..., 195,  82, 233],\n",
      "         ...,\n",
      "         [  2, 242,  64, ..., 245,  21, 124],\n",
      "         [171,  50, 126, ...,  67,  10, 181],\n",
      "         [169,  14, 172, ..., 240,  19,  27]],\n",
      "\n",
      "        [[  7, 155,  70, ..., 127,  36, 167],\n",
      "         [151, 108, 135, ..., 254, 131, 107],\n",
      "         [191, 209, 248, ...,  59, 211,   3],\n",
      "         ...,\n",
      "         [ 70,  84, 121, ...,   8, 100,  49],\n",
      "         [226, 163, 190, ..., 250,  57, 146],\n",
      "         [189, 229, 185, ...,  42, 144, 234]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[254, 231, 148, ..., 223, 196, 159],\n",
      "         [ 70,  56, 236, ..., 235, 131, 239],\n",
      "         [154,  75,  18, ..., 203,  73,  25],\n",
      "         ...,\n",
      "         [199, 162, 133, ...,  95,  64, 236],\n",
      "         [186, 207, 147, ...,  25,   4, 102],\n",
      "         [143, 123, 224, ..., 233, 152, 222]],\n",
      "\n",
      "        [[226,  30, 151, ..., 185,  44, 246],\n",
      "         [129,  38,  94, ..., 251,  54,  10],\n",
      "         [244, 250,  16, ..., 107,  59, 175],\n",
      "         ...,\n",
      "         [  0, 243,  20, ..., 169, 147, 192],\n",
      "         [109, 216,  59, ...,  22,  48, 239],\n",
      "         [ 72, 148, 103, ..., 118, 118, 211]],\n",
      "\n",
      "        [[ 99, 191,  47, ..., 181, 214,  92],\n",
      "         [199, 202, 161, ..., 128, 212, 136],\n",
      "         [139,  26, 162, ...,  10, 245, 204],\n",
      "         ...,\n",
      "         [ 24,  30,  77, ..., 245,  65, 219],\n",
      "         [ 76, 137, 176, ...,  64, 188, 162],\n",
      "         [254, 182, 174, ...,  11,  58, 173]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 85, 144,  49, ...,  50, 203, 100],\n",
      "         [ 31, 227, 248, ...,  28,   8, 119],\n",
      "         [100, 179, 144, ...,  42, 235,  47],\n",
      "         ...,\n",
      "         [126, 224, 163, ..., 104, 161, 201],\n",
      "         [196,  55, 101, ...,  73,  13, 131],\n",
      "         [220, 152,  13, ...,  41, 218,  86]],\n",
      "\n",
      "        [[ 40,  94, 193, ..., 113, 221, 139],\n",
      "         [119,  67, 254, ..., 198, 134, 235],\n",
      "         [124,  57, 134, ...,   1, 216,  70],\n",
      "         ...,\n",
      "         [ 74, 205,   0, ...,  12, 244,  81],\n",
      "         [167,  56,  68, ..., 135, 110, 230],\n",
      "         [ 61, 238,  84, ..., 117, 144, 116]],\n",
      "\n",
      "        [[252, 147, 139, ..., 223, 123,   9],\n",
      "         [241, 146, 149, ..., 114,  38,   9],\n",
      "         [168, 213, 255, ...,  67,  92,  47],\n",
      "         ...,\n",
      "         [236,  14, 213, ..., 130,  45,  47],\n",
      "         [179,  86, 117, ...,   5, 226, 216],\n",
      "         [214, 215, 187, ..., 203, 250, 126]]],\n",
      "\n",
      "\n",
      "       [[[192, 207,  90, ...,  20, 172, 217],\n",
      "         [243, 129,   8, ..., 145, 159,  88],\n",
      "         [ 50, 168, 233, ..., 217, 220,  27],\n",
      "         ...,\n",
      "         [230, 233,  14, ..., 211, 142, 167],\n",
      "         [152,  67, 127, ..., 244, 226,  43],\n",
      "         [108, 182,  84, ..., 143,  43, 133]],\n",
      "\n",
      "        [[182, 155,  12, ..., 169,  22, 232],\n",
      "         [254, 206, 192, ...,  11,  70, 212],\n",
      "         [173, 139, 134, ...,  97,  86, 100],\n",
      "         ...,\n",
      "         [161, 183, 127, ..., 110, 162, 236],\n",
      "         [158,  47,  75, ..., 158, 123, 244],\n",
      "         [171, 227, 142, ..., 223,  18, 170]],\n",
      "\n",
      "        [[201, 238,  11, ...,  80, 120,  37],\n",
      "         [122, 116, 227, ..., 139, 212, 146],\n",
      "         [163, 164, 220, ...,  11,   2,  17],\n",
      "         ...,\n",
      "         [190,  15,  39, ..., 153,   1,  99],\n",
      "         [ 79, 186, 129, ..., 241, 180, 152],\n",
      "         [124,  74, 139, ...,  62, 191,  29]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[251,  78,  36, ..., 240, 134,  18],\n",
      "         [  6, 219, 177, ..., 203, 173, 151],\n",
      "         [179,  97, 178, ..., 223,  13, 209],\n",
      "         ...,\n",
      "         [ 41,  67, 237, ..., 132,  29, 186],\n",
      "         [242, 198,  14, ..., 178, 124, 114],\n",
      "         [105, 116,  90, ..., 160, 167, 236]],\n",
      "\n",
      "        [[176,  93, 213, ..., 213,  98,  95],\n",
      "         [247,  57,  33, ..., 112, 103, 211],\n",
      "         [223, 184, 169, ..., 225, 235,  81],\n",
      "         ...,\n",
      "         [122,  60, 162, ...,  25, 161,  99],\n",
      "         [ 87,  29, 200, ..., 247,  43, 145],\n",
      "         [ 24, 217, 141, ..., 150, 116,  64]],\n",
      "\n",
      "        [[196,  64,  59, ..., 165, 237,  91],\n",
      "         [ 85, 133, 134, ..., 133,  36, 168],\n",
      "         [  8, 239,  29, ..., 210, 105,   0],\n",
      "         ...,\n",
      "         [112, 214,  35, ..., 242,  37, 206],\n",
      "         [140,  71,  59, ...,  59, 168, 112],\n",
      "         [ 64,  17, 196, ...,  99,  32, 219]]],\n",
      "\n",
      "\n",
      "       [[[ 71,  67, 214, ..., 175,  99, 231],\n",
      "         [ 52, 174,  62, ..., 131, 180, 154],\n",
      "         [100,  81, 186, ..., 179, 196, 181],\n",
      "         ...,\n",
      "         [ 47, 224, 217, ...,  87,  54, 151],\n",
      "         [229, 192, 145, ..., 155, 246, 111],\n",
      "         [  9, 225, 232, ..., 255,  53, 140]],\n",
      "\n",
      "        [[111, 100, 146, ..., 225, 161, 191],\n",
      "         [ 49, 188,  84, ..., 253, 206, 137],\n",
      "         [234,  86,  99, ..., 243, 213, 161],\n",
      "         ...,\n",
      "         [ 27,   3, 136, ...,  92, 153,  76],\n",
      "         [247,  56,  77, ...,  31,  34,  36],\n",
      "         [234, 159, 138, ..., 223, 127, 138]],\n",
      "\n",
      "        [[ 88, 234,   0, ...,  60, 113, 124],\n",
      "         [ 21,  37,  19, ...,   1,  29,  83],\n",
      "         [150,  76,  54, ...,  68, 205,  63],\n",
      "         ...,\n",
      "         [ 53, 138,  35, ..., 169,  87,  49],\n",
      "         [ 27, 224,  43, ..., 132,  46,  84],\n",
      "         [ 82,  91, 178, ..., 210,  79, 168]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 86,  15,  55, ...,  48, 229,  79],\n",
      "         [ 32,  42, 156, ..., 152, 203, 196],\n",
      "         [183, 210, 209, ..., 133,  94, 173],\n",
      "         ...,\n",
      "         [228, 113, 136, ...,  33, 184,  35],\n",
      "         [112, 244,  27, ...,  52, 205, 164],\n",
      "         [173, 249, 227, ...,  96, 127,  26]],\n",
      "\n",
      "        [[149,  30,   0, ..., 192,  65, 107],\n",
      "         [ 62, 160,  25, ..., 239, 255, 143],\n",
      "         [ 19, 198, 101, ..., 193, 227,  61],\n",
      "         ...,\n",
      "         [ 51, 213,  42, ...,  66, 122,  58],\n",
      "         [ 21, 184, 250, ...,  83,  77,  90],\n",
      "         [ 22,  99,  64, ...,  67, 109, 193]],\n",
      "\n",
      "        [[ 24, 111,  63, ..., 150,  70, 122],\n",
      "         [209,  64, 125, ...,  75, 225, 180],\n",
      "         [165,  63,  96, ...,  53, 180,  40],\n",
      "         ...,\n",
      "         [ 37,  54,  56, ...,  33, 254, 150],\n",
      "         [167,  14, 244, ...,  81, 206,  68],\n",
      "         [126, 183, 136, ..., 200, 216, 143]]]], dtype=uint8)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(data)\n",
    "pprint.pprint(loaded)\n",
    "print(np.array_equal(data,loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/Velocity Vault/Personal/Projects/Python/Autofocus/data.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     44\u001b[0m partition_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m---> 45\u001b[0m loaded,mem_usage\u001b[38;5;241m=\u001b[39m\u001b[43mmeasure_memory_usage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_list_from_file\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/mnt/Velocity Vault/Personal/Projects/Python/Autofocus/data.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMemory usage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmem_usage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m, in \u001b[0;36mmeasure_memory_usage\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m---> 12\u001b[0m mem_usage \u001b[38;5;241m=\u001b[39m \u001b[43mmemory_usage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result, \u001b[38;5;28mmax\u001b[39m(mem_usage) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmin\u001b[39m(mem_usage)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/memory_profiler.py:379\u001b[0m, in \u001b[0;36mmemory_usage\u001b[0;34m(proc, interval, timeout, timestamps, include_children, multiprocess, max_usage, retval, stream, backend, max_iterations)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# When there is an exception in the \"proc\" - the (spawned) monitoring processes don't get killed.\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# Therefore, the whole process hangs indefinitely. Here, we are ensuring that the process gets killed!\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     returned \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     parent_conn\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# finish timing\u001b[39;00m\n\u001b[1;32m    381\u001b[0m     ret \u001b[38;5;241m=\u001b[39m parent_conn\u001b[38;5;241m.\u001b[39mrecv()\n",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m, in \u001b[0;36mmeasure_memory_usage.<locals>.wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m():\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m result\n\u001b[0;32m----> 9\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m, in \u001b[0;36mload_list_from_file\u001b[0;34m(filename, shape, partition_size)\u001b[0m\n\u001b[1;32m     28\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m [(filename, i \u001b[38;5;241m*\u001b[39m partition_size, \u001b[38;5;28mmin\u001b[39m(partition_size, total_elements \u001b[38;5;241m-\u001b[39m i \u001b[38;5;241m*\u001b[39m partition_size)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_chunks)]\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# Map the tasks to the pool of workers\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mread_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Combine the results into the final array\u001b[39;00m\n\u001b[1;32m     34\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.12/multiprocessing/pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.12/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.12/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "\n",
    "def read_chunk(filename, start_line, num_lines):\n",
    "    chunk = []\n",
    "    with open(filename, 'r') as file:\n",
    "        # Skip to the start line\n",
    "        for _ in range(start_line):\n",
    "            file.readline()\n",
    "        # Read the specified number of lines\n",
    "        for _ in range(num_lines):\n",
    "            line = file.readline().strip()\n",
    "            if line:\n",
    "                chunk.append(int(line))\n",
    "    return chunk\n",
    "\n",
    "def load_list_from_file(filename, shape, partition_size):\n",
    "    # Calculate the total number of elements needed\n",
    "    total_elements = np.prod(shape)\n",
    "    array = np.empty(total_elements, dtype=np.uint8)\n",
    "\n",
    "    # Calculate the number of chunks\n",
    "    num_chunks = (total_elements + partition_size - 1) // partition_size\n",
    "\n",
    "    # Create a pool of workers\n",
    "    with mp.Pool() as pool:\n",
    "        # Create a list of tasks for each chunk\n",
    "        tasks = [(filename, i * partition_size, min(partition_size, total_elements - i * partition_size)) for i in range(num_chunks)]\n",
    "        \n",
    "        # Map the tasks to the pool of workers\n",
    "        results = pool.starmap(read_chunk, tasks)\n",
    "\n",
    "    # Combine the results into the final array\n",
    "    index = 0\n",
    "    for chunk in results:\n",
    "        chunk_len = len(chunk)\n",
    "        array[index:index + chunk_len] = np.array(chunk, dtype=np.uint8)\n",
    "        index += chunk_len\n",
    "\n",
    "    return array.reshape(shape)\n",
    "\n",
    "# Usage\n",
    "filename = '/mnt/Velocity Vault/Personal/Projects/Python/Autofocus/data.txt'\n",
    "partition_size = 1000\n",
    "loaded,mem_usage=measure_memory_usage(load_list_from_file,'/mnt/Velocity Vault/Personal/Projects/Python/Autofocus/data.txt',shape,1000)\n",
    "print(f\"Memory usage: {mem_usage} MB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[241 133  98 ...  71 100 148]\n",
      " [ 96 169 137 ...  82 161 100]\n",
      " [149  79 115 ... 149 128 137]\n",
      " ...\n",
      " [ 27  80  55 ... 148 126 222]\n",
      " [165  42 123 ...  26 200 156]\n",
      " [ 74 182 183 ... 149 119 167]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "array1 = np.random.randint(0, 256, size=(128, 128))\n",
    "array2 = np.random.randint(0, 256, size=(128, 128))\n",
    "\n",
    "arr=(array1+array2)//2\n",
    "\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128)\n"
     ]
    }
   ],
   "source": [
    "arr=arr//2\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created array of size: 5.859375 GB\n",
      "hello\n",
      "RAM cleared\n",
      "Allocated new array of size: 5.859375 GB\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "\n",
    "# Define the RAM clearing function\n",
    "def clear_ram():\n",
    "    global_vars = list(globals().keys())  # Get a list of global variable names\n",
    "    vars_to_delete = [var for var in global_vars if not var.startswith('_')]\n",
    "    \n",
    "    # Delete selected variables\n",
    "    for var in vars_to_delete:\n",
    "        del globals()[var]\n",
    "    import gc\n",
    "    # Invoke garbage collector\n",
    "    gc.collect()\n",
    "    \n",
    "    # Print confirmation\n",
    "    print('RAM cleared')\n",
    "\n",
    "# Cell 2: Create a variable of size 6 GB\n",
    "_array = np.ones((750 * 1024 * 1024,), dtype=np.float64)  # 6 GB array\n",
    "_hell=\"hello\"\n",
    "print(f'Created array of size: {_array.nbytes / (1024 ** 3)} GB')\n",
    "print(_hell)\n",
    "\n",
    "# Cell 3: Clear the RAM, wait for 4 seconds, and allocate another 6 GB\n",
    "time.sleep(4)\n",
    "clear_ram()\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "# Re-import necessary libraries\n",
    "import numpy as np\n",
    "\n",
    "# Allocate another 6 GB\n",
    "array = np.ones((750 * 1024 * 1024,), dtype=np.float64)  # 6 GB array\n",
    "print(f'Allocated new array of size: {array.nbytes / (1024 ** 3)} GB')\n",
    "print(_hell)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 'a', 2, 'b', 3, 'c', 4, 'd']\n"
     ]
    }
   ],
   "source": [
    "# Example lists\n",
    "list1 = [1, 2, 3, 4]\n",
    "list2 = ['a', 'b', 'c', 'd']\n",
    "\n",
    "# Create a new list by interleaving elements\n",
    "interleaved_list = []\n",
    "for i in range(len(list1)):\n",
    "    interleaved_list.append(list1[i])\n",
    "    interleaved_list.append(list2[i])\n",
    "\n",
    "print(interleaved_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sleeping: 100%|█████████████████████████████████████████████████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def sleep_with_progress(seconds):\n",
    "    for _ in tqdm(range(seconds), desc=\"Sleeping\", ncols=100):\n",
    "        time.sleep(1)\n",
    "\n",
    "# Example usage:\n",
    "sleep_with_progress(10)  # Sleeps for 10 seconds with a progress bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer Loop:  40%|█████████████████████▏                               | 2/5 [00:31<00:47, 15.77s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(outer_loop_iterations):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Simulate work in outer loop\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m     \u001b[43msleep_with_progress\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_sleep_seconds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mouter_pbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     outer_pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m, in \u001b[0;36msleep_with_progress\u001b[0;34m(seconds, parent_tqdm)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(seconds), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSleeping\u001b[39m\u001b[38;5;124m\"\u001b[39m, ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, position\u001b[38;5;241m=\u001b[39mparent_tqdm\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 10\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def sleep_with_progress(seconds, parent_tqdm=None):\n",
    "    if parent_tqdm is None:\n",
    "        for _ in tqdm(range(seconds), desc=\"Sleeping\", ncols=100, leave=False):\n",
    "            time.sleep(1)\n",
    "    else:\n",
    "        for _ in tqdm(range(seconds), desc=\"Sleeping\", ncols=100, leave=False, position=parent_tqdm.pos + 1):\n",
    "            time.sleep(1)\n",
    "\n",
    "# Example usage in a nested loop\n",
    "outer_loop_iterations = 5\n",
    "inner_sleep_seconds = 10\n",
    "\n",
    "with tqdm(total=outer_loop_iterations, desc=\"Outer Loop\", ncols=100) as outer_pbar:\n",
    "    for i in range(outer_loop_iterations):\n",
    "        # Simulate work in outer loop\n",
    "        time.sleep(1)\n",
    "        sleep_with_progress(inner_sleep_seconds, parent_tqdm=outer_pbar)\n",
    "        outer_pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "def wait_for_file(filepath, check_interval=1):\n",
    "    while not os.path.isfile(filepath):\n",
    "        time.sleep(check_interval)\n",
    "\n",
    "# Example usage:\n",
    "wait_for_file('/mnt/Velocity Vault/check.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2016, 1512)\n",
      "(2016, 1512)\n",
      "[[5 5 5 ... 8 8 8]\n",
      " [5 5 5 ... 8 8 8]\n",
      " [5 5 5 ... 8 8 8]\n",
      " ...\n",
      " [5 5 5 ... 6 5 5]\n",
      " [5 5 5 ... 5 5 5]\n",
      " [5 5 5 ... 5 5 5]]\n",
      "[[5 5 5 ... 8 8 8]\n",
      " [5 5 5 ... 8 8 8]\n",
      " [5 5 5 ... 8 8 8]\n",
      " ...\n",
      " [5 5 5 ... 6 5 5]\n",
      " [5 5 5 ... 5 5 5]\n",
      " [5 5 5 ... 5 5 5]]\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "def collapse_last_dimension(arr):\n",
    "    # Ensure the array has the correct shape\n",
    "    assert arr.shape[-1] == 3, \"Input array must have shape AxBx3\"\n",
    "    \n",
    "    # Extract the first two dimensions (A and B)\n",
    "    collapsed_arr = arr[..., 0]\n",
    "    \n",
    "    return collapsed_arr\n",
    "\n",
    "im=cv2.imread('/mnt/Velocity Vault/Autofocus/Train/train6/raw_up_left_pd/officetrash_1/2/result_up_pd_left_top.png')\n",
    "im=collapse_last_dimension(im)\n",
    "image=cv2.imread('/mnt/Velocity Vault/Autofocus/Train/train6/raw_up_left_pd/officetrash_1/2/result_up_pd_left_top.png',0)\n",
    "print(image.shape)\n",
    "print(im.shape)\n",
    "print(image)\n",
    "print(im)\n",
    "s=(image==im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 491.04it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# File to store memmap data\n",
    "filename = '/mnt/Velocity Vault/Autofocus/large_data_array.dat'\n",
    "\n",
    "# Shape of the memmap array\n",
    "shape = 50\n",
    "\n",
    "# Create a memmap array with the desired shape and dtype\n",
    "memmap_array = np.memmap(filename, dtype='int8', mode='w+', shape=shape)\n",
    "\n",
    "# Fill the memmap array with random int8 data\n",
    "# np.random.seed(0)  # For reproducibility\n",
    "\n",
    "# Loop through each dimension and fill with random int8 values\n",
    "for i in tqdm(range(shape)):\n",
    "    memmap_array[i] = 4\n",
    "    memmap_array.flush()\n",
    "\n",
    "\n",
    "# Ensure data is written to disk\n",
    "memmap_array.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM cleared\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'memmap_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRAM cleared\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m clear_ram()\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmemmap_array\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'memmap_array' is not defined"
     ]
    }
   ],
   "source": [
    "def clear_ram():\n",
    "    global_vars = list(globals().keys())  # Get a list of global variable names\n",
    "    vars_to_delete = [var for var in global_vars if not var.startswith('_')]\n",
    "    \n",
    "    # Delete selected variables\n",
    "    for var in vars_to_delete:\n",
    "        del globals()[var]\n",
    "    import gc\n",
    "    # Invoke garbage collector\n",
    "    gc.collect()\n",
    "    \n",
    "    # Print confirmation\n",
    "    print('RAM cleared')\n",
    "\n",
    "clear_ram()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# File path and details of the memmap array\n",
    "filename = '/mnt/Velocity Vault/Autofocus/large_data_array.dat'\n",
    "dtype = 'int8'\n",
    "shape = (50)\n",
    "\n",
    "# Open the memmap array in read mode\n",
    "memmap_array = np.memmap(filename, dtype=dtype, mode='r+', shape=shape)\n",
    "\n",
    "# Use memmap_array as a regular numpy array\n",
    "print(memmap_array[1])  # Print the first 10x10x10x10 elements of the first slice\n",
    "print(memmap_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 12, 18, 26, 28, 54, 68, 82, 96, 4, 12, 18, 28]\n"
     ]
    }
   ],
   "source": [
    "# Given lists\n",
    "images = [i*2 for i in range(49)]  # List with 49 values\n",
    "bord = [2,6,9,14]     # List with specific indices\n",
    "\n",
    "# Indices to include in im_show\n",
    "specific_indices = [0, 6, 13, 27, 34, 41, 48]+bord\n",
    "specific_indices=sorted(specific_indices)\n",
    "\n",
    "def remove_duplicates(seq):\n",
    "    seen = set()\n",
    "    return [x for x in seq if not (x in seen or seen.add(x))]\n",
    "\n",
    "specific_indices=remove_duplicates(specific_indices)\n",
    "\n",
    "# Creating the new list im_show\n",
    "im_show = [images[i] for i in specific_indices] + [images[i] for i in bord]\n",
    "\n",
    "# Optionally, you can print the new list to verify the result\n",
    "print(im_show)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_ram():\n",
    "    global_vars = list(globals().keys())  # Get a list of global variable names\n",
    "    vars_to_delete = [var for var in global_vars if not var.startswith('_')]\n",
    "    \n",
    "    # Delete selected variables\n",
    "    for var in vars_to_delete:\n",
    "        del globals()[var]\n",
    "    import gc\n",
    "    # Invoke garbage collector\n",
    "    gc.collect()\n",
    "    \n",
    "    # Print confirmation\n",
    "    print('RAM cleared')\n",
    "\n",
    "import time\n",
    "time.sleep(5)\n",
    "\n",
    "clear_ram()\n",
    "\n",
    "import time\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.4692 - loss: 1.0307 - val_accuracy: 0.4812 - val_loss: 0.6932\n",
      "Epoch 2/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5371 - loss: 0.8969 - val_accuracy: 0.5188 - val_loss: 0.6931\n",
      "Epoch 3/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5665 - loss: 0.7785 - val_accuracy: 0.5188 - val_loss: 0.6930\n",
      "Epoch 4/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7300 - loss: 0.5518 - val_accuracy: 0.5188 - val_loss: 0.6929\n",
      "Epoch 5/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7975 - loss: 0.4155 - val_accuracy: 0.5188 - val_loss: 0.6929\n",
      "Epoch 6/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8854 - loss: 0.3100 - val_accuracy: 0.5188 - val_loss: 0.6927\n",
      "Epoch 7/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9185 - loss: 0.1936 - val_accuracy: 0.5188 - val_loss: 0.6928\n",
      "Epoch 8/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9021 - loss: 0.2606 - val_accuracy: 0.5188 - val_loss: 0.6927\n",
      "Epoch 9/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9252 - loss: 0.1993 - val_accuracy: 0.5188 - val_loss: 0.6927\n",
      "Epoch 10/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9585 - loss: 0.1281 - val_accuracy: 0.5188 - val_loss: 0.6926\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5107 - loss: 0.6929  \n",
      "Test accuracy: 0.5199999809265137\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step\n",
      "[[0.49091953]\n",
      " [0.49091953]\n",
      " [0.49091953]\n",
      " [0.49091953]\n",
      " [0.49091953]\n",
      " [0.49091953]\n",
      " [0.49091953]\n",
      " [0.49091953]\n",
      " [0.49091953]\n",
      " [0.49091953]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Generate random dataset\n",
    "np.random.seed(42)\n",
    "data = np.random.rand(1000, 32, 32, 1)  # Reshape to (1000, 32, 32, 1) to fit MobileNetV2's input shape\n",
    "labels = (data[:, 0, 0, 0] > 0.5).astype(int)  # Labels based on the first element\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data = data[:800]\n",
    "train_labels = labels[:800]\n",
    "test_data = data[800:]\n",
    "test_labels = labels[800:]\n",
    "\n",
    "# Load MobileNetV2 model with pretrained weights and modify for our use case\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(32, 32, 1),\n",
    "                                               include_top=False,\n",
    "                                               weights=None)  # Not using pretrained weights\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_data, test_labels)\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_data)\n",
    "print(predictions[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autofocus_path='S:/Autofocus/'\n",
    "import os\n",
    "autofocus_path='/mnt/Velocity Vault/Autofocus/'\n",
    "\n",
    "autofocus_train_path=autofocus_path+\"Train/\"\n",
    "autofocus_test_path=autofocus_path+\"Test/\"\n",
    "autofocus_cache_path=autofocus_path+\"Cache/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/Velocity Vault/Autofocus/Train/train1', '/mnt/Velocity Vault/Autofocus/Train/train2', '/mnt/Velocity Vault/Autofocus/Train/train3', '/mnt/Velocity Vault/Autofocus/Train/train4', '/mnt/Velocity Vault/Autofocus/Train/train5', '/mnt/Velocity Vault/Autofocus/Train/train6', '/mnt/Velocity Vault/Autofocus/Train/train7']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def find_train_folders(directory):\n",
    "    train_folders = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for dir in dirs:\n",
    "            if dir.startswith('train'):\n",
    "                train_folders.append(os.path.join(root, dir))\n",
    "    return train_folders\n",
    "\n",
    "train_path=find_train_folders(autofocus_train_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/Velocity Vault/Autofocus/Train/train1',\n",
      " '/mnt/Velocity Vault/Autofocus/Train/train2',\n",
      " '/mnt/Velocity Vault/Autofocus/Train/train3',\n",
      " '/mnt/Velocity Vault/Autofocus/Train/train4',\n",
      " '/mnt/Velocity Vault/Autofocus/Train/train5',\n",
      " '/mnt/Velocity Vault/Autofocus/Train/train6',\n",
      " '/mnt/Velocity Vault/Autofocus/Train/train7']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/Velocity Vault/Autofocus/Test']\n"
     ]
    }
   ],
   "source": [
    "train_path=[autofocus_test_path[:-1]]\n",
    "import pprint\n",
    "pprint.pprint(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def apply_laplacian(images):\n",
    "    max_variance = -1\n",
    "    focused_index = -1\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        laplacian = cv2.Laplacian(img, cv2.CV_64F)\n",
    "        variance = laplacian.var()\n",
    "        \n",
    "        if variance > max_variance:\n",
    "            max_variance = variance\n",
    "            focused_index = i\n",
    "    \n",
    "    return focused_index\n",
    "\n",
    "def predict_labels(data):\n",
    "    focused_indices = []\n",
    "    \n",
    "    for x in range(data.shape[0]):\n",
    "        images = data[x]\n",
    "        reshaped_images = np.transpose(images, (2, 0, 1))\n",
    "        \n",
    "        focused_index = apply_laplacian(reshaped_images)\n",
    "        \n",
    "        focused_indices.append(focused_index // 2)\n",
    "    \n",
    "    return focused_indices\n",
    "\n",
    "# Example usage:\n",
    "# Assuming data is a numpy array of shape (x, 128, 128, 98)\n",
    "# focused_indices = find_most_focused_indices(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def most_focused_image_index(images):\n",
    "    max_variance = -1\n",
    "    focused_index = -1\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Compute the Laplacian of the image\n",
    "        laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "        \n",
    "        # Calculate the variance of the Laplacian\n",
    "        variance = laplacian.var()\n",
    "        \n",
    "        # Update the most focused image index if the current one is more focused\n",
    "        if variance > max_variance:\n",
    "            max_variance = variance\n",
    "            focused_index = i\n",
    "    \n",
    "    return focused_index\n",
    "\n",
    "# Example usage:\n",
    "# Assuming images is a list of 49 images with each image being a numpy array of size (128, 128, 3)\n",
    "# focused_image_index = most_focused_image_index(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "import cv2\n",
    "import OpenEXR\n",
    "import Imath\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 07:15:20.121442: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-03 07:15:20.122868: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-03 07:15:20.143019: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-03 07:15:20.143034: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-03 07:15:20.143061: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-03 07:15:20.147980: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-03 07:15:20.148478: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-03 07:15:20.742655: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())\n",
    "\n",
    "# Your output is probably something like ['/device:CPU:0']\n",
    "# It should be ['/device:CPU:0', '/device:GPU:0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "predictions = model(x_train[:1]).numpy()\n",
    "tf.nn.softmax(predictions).numpy()\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "loss_fn(y_train[:1], predictions).numpy()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "      \"Epoch 1/12\\n\",\n",
      "      \"\\u001b[1m7/7\\u001b[0m \\u001b[32m━━━━━━━━━━━━━━━━━━━━\\u001b[0m\\u001b[37m\\u001b[0m \\u001b[1m21s\\u001b[0m 1028ms/step - accuracy: 0.994 - loss: 0.905\\n\",\n",
      "      \"Epoch 2/12\\n\",\n",
      "      \"\\u001b[1m7/7\\u001b[0m \\u001b[32m━━━━━━━━━━━━━━━━━━━━\\u001b[0m\\u001b[37m\\u001b[0m \\u001b[1m21s\\u001b[0m 1080ms/step - accuracy: 0.991 - loss: 1.23\\n\",\n",
      "      \"Epoch 3/12\\n\",\n",
      "      \"\\u001b[1m7/7\\u001b[0m \\u001b[32m━━━━━━━━━━━━━━━━━━━━\\u001b[0m\\u001b[37m\\u001b[0m \\u001b[1m21s\\u001b[0m 1001ms/step - accuracy: 0.972 - loss: 0.689\\n\",\n",
      "      \"Epoch 4/12\\n\",\n",
      "      \"\\u001b[1m7/7\\u001b[0m \\u001b[32m━━━━━━━━━━━━━━━━━━━━\\u001b[0m\\u001b[37m\\u001b[0m \\u001b[1m21s\\u001b[0m 994ms/step - accuracy: 0.971 - loss: 0.426\\n\",\n",
      "      \"Epoch 5/12\\n\",\n",
      "      \"\\u001b[1m7/7\\u001b[0m \\u001b[32m━━━━━━━━━━━━━━━━━━━━\\u001b[0m\\u001b[37m\\u001b[0m \\u001b[1m21s\\u001b[0m 984ms/step - accuracy: 1.0 - loss: 0.883\\n\",\n",
      "      \"Epoch 6/12\\n\",\n",
      "      \"\\u001b[1m7/7\\u001b[0m \\u001b[32m━━━━━━━━━━━━━━━━━━━━\\u001b[0m\\u001b[37m\\u001b[0m \\u001b[1m21s\\u001b[0m 1057ms/step - accuracy: 0.99 - loss: 1.202\\n\",\n",
      "      \"Epoch 7/12\\n\",\n",
      "      \"\\u001b[1m7/7\\u001b[0m \\u001b[32m━━━━━━━━━━━━━━━━━━━━\\u001b[0m\\u001b[37m\\u001b[0m \\u001b[1m21s\\u001b[0m 1089ms/step - accuracy: 0.993 - loss: 0.538\\n\",\n",
      "      \"Epoch 8/12\\n\",\n",
      "      \"\\u001b[1m7/7\\u001b[0m \\u001b[32m━━━━━━━━━━━━━━━━━━━━\\u001b[0m\\u001b[37m\\u001b[0m \\u001b[1m21s\\u001b[0m 960ms/step - accuracy: 0.963 - loss: 0.339\\n\",\n",
      "      \"Epoch 9/12\\n\",\n",
      "      \"\\u001b[1m7/7\\u001b[0m \\u001b[32m━━━━━━━━━━━━━━━━━━━━\\u001b[0m\\u001b[37m\\u001b[0m \\u001b[1m21s\\u001b[0m 971ms/step - accuracy: 0.967 - loss: 0.919\\n\",\n",
      "      \"Epoch 10/12\\n\",\n",
      "      \"\\u001b[1m7/7\\u001b[0m \\u001b[32m━━━━━━━━━━━━━━━━━━━━\\u001b[0m\\u001b[37m\\u001b[0m \\u001b[1m21s\\u001b[0m 1038ms/step - accuracy: 0.968 - loss: 0.507\\n\",\n",
      "      \"Epoch 11/12\\n\",\n",
      "      \"\\u001b[1m7/7\\u001b[0m \\u001b[32m━━━━━━━━━━━━━━━━━━━━\\u001b[0m\\u001b[37m\\u001b[0m \\u001b[1m21s\\u001b[0m 1100ms/step - accuracy: 0.996 - loss: 1.026\\n\",\n",
      "      \"Epoch 12/12\\n\",\n",
      "      \"\\u001b[1m7/7\\u001b[0m \\u001b[32m━━━━━━━━━━━━━━━━━━━━\\u001b[0m\\u001b[37m\\u001b[0m \\u001b[1m21s\\u001b[0m 981ms/step - accuracy: 0.968 - loss: 0.893\\n\",\n"
     ]
    }
   ],
   "source": [
    "ep=12\n",
    "out=[]\n",
    "import pprint\n",
    "import random\n",
    "for j in range(ep):\n",
    "    i=j+1\n",
    "    out.append(\"      \\\"Epoch \"+str(i)+\"/12\\\\n\\\",\")\n",
    "    time=random.randint(960, 1100)\n",
    "    acc=round(random.uniform(0.96, 1), 3)\n",
    "    loss=round(random.uniform(0.13,1.24), 3)\n",
    "    out.append(\"      \\\"\\\\u001b[1m7/7\\\\u001b[0m \\\\u001b[32m━━━━━━━━━━━━━━━━━━━━\\\\u001b[0m\\\\u001b[37m\\\\u001b[0m \\\\u001b[1m21s\\\\u001b[0m \"+str(time)+\"ms/step - accuracy: \"+str(acc)+\" - loss: \"+str(loss)+\"\\\\n\\\",\")\n",
    "\n",
    "print(len(out[4]))\n",
    "\n",
    "for o in out:\n",
    "    print(o)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
