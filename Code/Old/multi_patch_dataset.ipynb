{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def build_depth_map(super_path):\n",
    "    depth_map_path = {}\n",
    "\n",
    "    # Walk through the directory tree\n",
    "    for root, _, files in os.walk(super_path):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.png'):\n",
    "                full_path = os.path.join(root, filename)\n",
    "                # Remove super_path from the full path to get the relative path\n",
    "                relative_path = os.path.relpath(full_path, super_path)\n",
    "                # Split the relative path into parts (folders)\n",
    "                parts = relative_path.split(os.sep)\n",
    "                parts[-1]=parts[-1][len('result_merged_depth_'):-len('.png')]\n",
    "                \n",
    "                # Initialize nested dictionaries as needed\n",
    "                current_dict = depth_map_path\n",
    "                for part in parts[:-1]:  # Iterate over all parts except the last one (filename)\n",
    "                    current_dict = current_dict.setdefault(part, {})\n",
    "                \n",
    "                # Assign the full path to the deepest nested dictionary\n",
    "                current_dict[parts[-1]] = full_path\n",
    "\n",
    "    return depth_map_path\n",
    "\n",
    "def build_depth_map_confidence(super_path):\n",
    "    depth_map_path = {}\n",
    "\n",
    "    # Walk through the directory tree\n",
    "    for root, _, files in os.walk(super_path):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.exr'):\n",
    "                full_path = os.path.join(root, filename)\n",
    "                # Remove super_path from the full path to get the relative path\n",
    "                relative_path = os.path.relpath(full_path, super_path)\n",
    "                # Split the relative path into parts (folders)\n",
    "                parts = relative_path.split(os.sep)\n",
    "                parts[-1]=parts[-1][len('result_merged_conf_'):-len('.exr')]\n",
    "                \n",
    "                # Initialize nested dictionaries as needed\n",
    "                current_dict = depth_map_path\n",
    "                for part in parts[:-1]:  # Iterate over all parts except the last one (filename)\n",
    "                    current_dict = current_dict.setdefault(part, {})\n",
    "                \n",
    "                # Assign the full path to the deepest nested dictionary\n",
    "                current_dict[parts[-1]] = full_path\n",
    "\n",
    "    return depth_map_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def find_train_folders(directory):\n",
    "    train_folders = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for dir in dirs:\n",
    "            if dir.startswith('train'):\n",
    "                train_folders.append(os.path.join(root, dir))\n",
    "    return train_folders\n",
    "\n",
    "train_path=find_train_folders('/mnt/Velocity Vault/Personal/Projects/Python/Autofocus/Train/')\n",
    "\n",
    "depth_map_path={}\n",
    "depth_map_path_temp={}\n",
    "\n",
    "for path in train_path:\n",
    "    depth_map_path_temp=build_depth_map(path+\"/merged_depth\")\n",
    "    depth_map_path.update(depth_map_path_temp)\n",
    "\n",
    "depth_map_confidence_path={}\n",
    "depth_map_confidence_path_temp={}\n",
    "\n",
    "for path in train_path:\n",
    "    depth_map_confidence_path_temp=build_depth_map_confidence(path+\"/merged_conf\")\n",
    "    depth_map_confidence_path.update(depth_map_confidence_path_temp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(depth_map_path)\n",
    "pprint.pprint(depth_map_confidence_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def generate_random_patches(size=(504,378)):\n",
    "    image=np.zeros(size)\n",
    "    patches=[]\n",
    "    for _ in (range(100)):\n",
    "        x=random.randint(16, 487)\n",
    "        y=random.randint(16, 361)\n",
    "\n",
    "        #print(x,y)\n",
    "        \n",
    "        breaker=False\n",
    "\n",
    "        for i in range(x-26,x+26):\n",
    "            for j in range(y-26,y+26):\n",
    "                if i<0 or i>503 or j<0 or j>377 :\n",
    "                    continue\n",
    "                if image[i][j]==1:\n",
    "                    breaker=True\n",
    "                    break\n",
    "            if breaker:\n",
    "                break\n",
    "\n",
    "        if breaker:\n",
    "            continue\n",
    "        \n",
    "        x=x-16\n",
    "        y=y-16\n",
    "\n",
    "        for i in range(x,x+33):\n",
    "            for j in range(y,y+33):\n",
    "                image[i][j]=1\n",
    "\n",
    "        patches.append((x,y))\n",
    "\n",
    "\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import OpenEXR\n",
    "import Imath\n",
    "\n",
    "def load_exr(file_path):\n",
    "    exr_file = OpenEXR.InputFile(file_path)\n",
    "    header = exr_file.header()\n",
    "    dw = header['dataWindow']\n",
    "    width = dw.max.x - dw.min.x + 1\n",
    "    height = dw.max.y - dw.min.y + 1\n",
    "    pt = Imath.PixelType(Imath.PixelType.FLOAT)\n",
    "    r = np.frombuffer(exr_file.channel('R', pt), dtype=np.float32)\n",
    "    r.shape = (height, width)\n",
    "    return r\n",
    "\n",
    "def predict_patches(depth_confidence_path):\n",
    "    depth_map_confidence = load_exr(depth_confidence_path)\n",
    "\n",
    "    all_patches=generate_random_patches()\n",
    "\n",
    "    confidence_patch_blocks=[depth_map_confidence[x:x+32,y:y+32] for (x,y) in all_patches]\n",
    "    median_confidence_patch_block=[np.median(patch.flatten()) for patch in confidence_patch_blocks]\n",
    "\n",
    "    patch_indices=[i for i, value in enumerate(median_confidence_patch_block) if value >= 0.98]\n",
    "\n",
    "    if len(patch_indices)>4:\n",
    "        patch_indices = sorted(range(len(median_confidence_patch_block)), key=lambda i: median_confidence_patch_block[i], reverse=True)[:4]\n",
    "\n",
    "    patches=[all_patches[patch_index] for patch_index in patch_indices]\n",
    "\n",
    "    return patches\n",
    "\n",
    "def predict_focal_length(depth_map_path,patch):\n",
    "    depth_map = cv2.imread(depth_map_path, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "\n",
    "    depth_values=depth_map[patch[0]:patch[0]+32,patch[1]:patch[1]+32]\n",
    "    depth_values=depth_values.flatten()\n",
    "\n",
    "    # Define max and min values\n",
    "    max_depth = 100.0\n",
    "    min_depth = 0.2\n",
    "\n",
    "    depth_map_in_meters = (max_depth * min_depth) / (max_depth - (max_depth - min_depth) * (depth_values / 255.0))\n",
    "\n",
    "    # Compute the median value in the entire depth map\n",
    "    median_depth = np.median(depth_map_in_meters)\n",
    "\n",
    "    final_focus=median_depth*1000\n",
    "\n",
    "    return final_focus\n",
    "\n",
    "slice_focal_length=[3910.92,2289.27,1508.71,1185.83,935.91,801.09,700.37,605.39,546.23,486.87,447.99,407.40,379.91,350.41,329.95,307.54,291.72,274.13,261.53,247.35,237.08,225.41,216.88,207.10,198.18,191.60,183.96,178.29,171.69,165.57,160.99,155.61,150.59,146.81,142.35,138.98,134.99,131.23,127.69,124.99,121.77,118.73,116.40,113.63,110.99,108.47,106.54,104.23,102.01]\n",
    "\n",
    "def find_closest(value, num_list):\n",
    "    closest_value = min(num_list, key=lambda x: abs(x - value))\n",
    "    return closest_value\n",
    "\n",
    "def predict_slice(depth_map_path,depth_confidence_path):\n",
    "    truth=[]\n",
    "\n",
    "    patches=predict_patches(depth_confidence_path)\n",
    "    \n",
    "    for patch in patches:\n",
    "        predicted_focus=predict_focal_length(depth_map_path,patch)\n",
    "        closest_value = find_closest(predicted_focus, slice_focal_length)\n",
    "        true_slice=slice_focal_length.index(closest_value)\n",
    "        true_slice=true_slice-1 if true_slice !=0 else true_slice\n",
    "        truth.append((patch[0],patch[1],true_slice))\n",
    "\n",
    "    return truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "ground_truth=copy.deepcopy(depth_map_path)\n",
    "\n",
    "for image_type in tqdm(ground_truth):\n",
    "    for pos in ground_truth[image_type]:\n",
    "        ground_truth[image_type][pos]=predict_slice(depth_map_path[image_type][pos],depth_map_confidence_path[image_type][pos])\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_count=[]\n",
    "\n",
    "for key1 in ground_truth:\n",
    "    for key2 in ground_truth[key1]:\n",
    "        patch_count.append(len(ground_truth[key1][key2]))\n",
    "\n",
    "print(min(patch_count),\" \",np.mean(patch_count),\" \",max(patch_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def generate_image_paths(super_path):\n",
    "    # Initialize the dictionary\n",
    "    image_path = {}\n",
    "\n",
    "    # Traverse the directory structure\n",
    "    for root, dirs, files in os.walk(super_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.png'):\n",
    "                # Get the relative path from super_path\n",
    "                relative_path = os.path.relpath(root, super_path)\n",
    "                # Split the relative path to get <string> and <integer>\n",
    "                string_part, integer_part = os.path.split(relative_path)\n",
    "                integer_part = int(integer_part)\n",
    "                \n",
    "                # Extract the position from the filename\n",
    "                file_name_parts = file.split('_')\n",
    "                position = file_name_parts[-1].split('.')[0]  # Extract 'bottom', 'top', etc.\n",
    "                \n",
    "                # Construct the full file path\n",
    "                full_file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Populate the dictionary\n",
    "                if string_part not in image_path:\n",
    "                    image_path[string_part] = {}\n",
    "                if integer_part not in image_path[string_part]:\n",
    "                    image_path[string_part][integer_part] = {}\n",
    "                \n",
    "                image_path[string_part][integer_part][position] = full_file_path\n",
    "\n",
    "    return image_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "left_image_path = {}\n",
    "left_image_path_temp = {}\n",
    "right_image_path = {}\n",
    "right_image_path_temp = {}\n",
    "\n",
    "\n",
    "def find_train_folders(directory):\n",
    "    train_folders = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for dir in dirs:\n",
    "            if dir.startswith('train'):\n",
    "                train_folders.append(os.path.join(root, dir))\n",
    "    return train_folders\n",
    "\n",
    "\n",
    "train_path = find_train_folders(\n",
    "    '/mnt/Velocity Vault/Personal/Projects/Python/Autofocus/Train/')\n",
    "\n",
    "\n",
    "for path in train_path:\n",
    "    left_image_path_temp = generate_image_paths(path+'/raw_up_left_pd')\n",
    "    left_image_path.update(left_image_path_temp)\n",
    "    right_image_path_temp = generate_image_paths(path+'/raw_up_right_pd')\n",
    "    right_image_path.update(right_image_path_temp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_image_path(image_path):\n",
    "    ip = {}\n",
    "\n",
    "    for key1, level2_dict in image_path.items():\n",
    "        for key2, level3_dict in level2_dict.items():\n",
    "            for key3, value in level3_dict.items():\n",
    "                if key1 not in ip:\n",
    "                    ip[key1] = {}\n",
    "                if key3 not in ip[key1]:\n",
    "                    ip[key1][key3] = []\n",
    "                ip[key1][key3].append(value)\n",
    "\n",
    "    return ip\n",
    "\n",
    "left_image_path=reorder_image_path(left_image_path)\n",
    "right_image_path=reorder_image_path(right_image_path)\n",
    "\n",
    "\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(left_image_path)\n",
    "pprint.pprint(right_image_path)\n",
    "print(len(left_image_path))\n",
    "print(len(right_image_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_image_paths(left_image_path,right_image_path):\n",
    "    image_paths=copy.deepcopy(left_image_path)\n",
    "    for key1 in image_paths:\n",
    "        for key2 in image_paths[key1]:\n",
    "            image_paths[key1][key2]=left_image_path[key1][key2]+right_image_path[key1][key2]\n",
    "    return image_paths\n",
    "\n",
    "image_paths=combine_image_paths(left_image_path,right_image_path)\n",
    "\n",
    "pprint.pprint(image_paths)\n",
    "print(len(image_paths))\n",
    "print(type(image_paths['apt1_0']['center']))\n",
    "print(len(image_paths['apt1_0']['center']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_last_dimension(arr):\n",
    "    # Ensure the array has the correct shape\n",
    "    assert arr.shape[-1] == 3, \"Input array must have shape AxBx3\"\n",
    "    \n",
    "    # Extract the first two dimensions (A and B)\n",
    "    collapsed_arr = arr[..., 0]\n",
    "    \n",
    "    return collapsed_arr\n",
    "\n",
    "def combine_last_dimension(arrays):\n",
    "    A = arrays[0].shape[0]  # Assuming all arrays have the same shape AxA\n",
    "    s = len(arrays)\n",
    "    \n",
    "    # Initialize the resulting array with lists\n",
    "    list_array = np.empty((A, A, s), dtype=object)\n",
    "    \n",
    "    # Fill the array with corresponding elements from each input array\n",
    "    for k, array in enumerate(arrays):\n",
    "        list_array[..., k] = array\n",
    "    \n",
    "    return list_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def build_dataset_labels(image_paths,ground_truth):\n",
    "    dataset=[]\n",
    "    labels=[]\n",
    "\n",
    "    for image_type in tqdm(ground_truth):\n",
    "        for pos in ground_truth[image_type]:\n",
    "            temp=ground_truth[image_type][pos]\n",
    "            patches=[(x,y) for (x,y,_) in temp]\n",
    "            truth=[z for (_,_,z) in temp]\n",
    "\n",
    "            for patch in patches:\n",
    "                image_path=image_paths[image_type][pos]\n",
    "                images=[]\n",
    "                for path in image_path:\n",
    "                    x=patch[0]*4\n",
    "                    y=patch[1]*4\n",
    "                    image=cv2.imread(path)\n",
    "                    image=collapse_last_dimension(image)\n",
    "                    image=image[x:x+128,y:y+128]\n",
    "                    images.append(image)\n",
    "                image_set=combine_last_dimension(images)\n",
    "                dataset.append(image_set)\n",
    "                labels.append(truth)\n",
    "\n",
    "    return dataset,labels\n",
    "\n",
    "dataset,labels=build_dataset_labels(image_paths,ground_truth)\n",
    "\n",
    "pprint.pprint(dataset)\n",
    "pprint.pprint(labels)\n",
    "print(len(dataset))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0].shape)\n",
    "\n",
    "def check_shapes(lst):\n",
    "    target_shape = (128, 128, 98)\n",
    "    for element in lst:\n",
    "        if not isinstance(element, np.ndarray) or element.shape != target_shape:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "print(check_shapes(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_list_to_file(dataset, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(dataset, file)\n",
    "\n",
    "def load_list_from_file(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_list_to_file(dataset,'dataset_cache.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#save_list_to_file(dataset,'dataset_cache.pkl')\n",
    "\n",
    "loaded_dataset=load_list_from_file('dataset_cache.pkl')\n",
    "\n",
    "pprint.pprint(loaded_dataset)\n",
    "print(len(loaded_dataset))\n",
    "print(check_shapes(loaded_dataset))\n",
    "\n",
    "#print(dataset==loaded_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Step 1: Modify MobileNetV2 to accept 128x128x98 input\n",
    "def create_modified_mobilenetv2(input_shape=(128, 128, 98)):\n",
    "    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights=None)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # Assuming the output for the ordinal regression problem is a single value\n",
    "    outputs = Dense(1)(x)\n",
    "    model = Model(inputs=base_model.input, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Step 2: Implement the ordinal regression loss\n",
    "def ordinal_regression_loss(y_true, y_pred):\n",
    "    # L2 loss (mean squared error)\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Step 3: Set up the training loop\n",
    "def train_model(model, train_dataset, steps_per_epoch=20000, batch_size=128, initial_lr=1e-3, beta1=0.5, beta2=0.999):\n",
    "    optimizer = Adam(learning_rate=initial_lr, beta_1=beta1, beta_2=beta2)\n",
    "    model.compile(optimizer=optimizer, loss=ordinal_regression_loss)\n",
    "    \n",
    "    model.fit(train_dataset, epochs=int(steps_per_epoch // (len(train_dataset) / batch_size)), steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "# Create the model\n",
    "input_shape = (128, 128, 98)\n",
    "model = create_modified_mobilenetv2(input_shape=input_shape)\n",
    "\n",
    "x_train=dataset.copy()\n",
    "y_train=labels.copy()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32).shuffle(buffer_size=10000)\n",
    "\n",
    "train_model(model, train_dataset, steps_per_epoch=59, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
