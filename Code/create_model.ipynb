{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 01:31:19.378713: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-20 01:31:19.410925: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-20 01:31:19.410964: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-20 01:31:19.411971: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-20 01:31:19.417309: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-20 01:31:21.135757: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n",
      "WARNING:tensorflow:From /tmp/ipykernel_44256/1102023886.py:33: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU Available: True\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4587412722181471871\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3784300953\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11075676784906228803\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 01:31:23.828894: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:23.876539: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:23.877610: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:23.954587: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:23.955747: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:23.956801: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:23.958134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3608 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-01-20 01:31:23.959937: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:23.961363: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:23.962784: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:23.963789: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:23.964717: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:23.965623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 3608 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-01-20 01:31:23.966304: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:23.967279: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:23.968203: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:23.969154: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:23.970108: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:23.971016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 3608 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.environ[\"TF_GPU_THREAD_MODE\"] = \"gpu_private\"\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "# from keras.optimizers import SGD\n",
    "from keras.utils import Sequence\n",
    "\n",
    "# os.environ[\"TF_DATA_EXPERIMENTAL_OPTIMIZATION_AUTOTUNE_RAM_BUDGET\"] = \"18884901888\"\n",
    "\n",
    "\n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.95)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#         print(\"Memory growth enabled for GPUs\")\n",
    "#     except RuntimeError as e:\n",
    "#         print(f\"Error enabling memory growth: {e}\")\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.test.is_gpu_available())\n",
    "\n",
    "# Get detailed device information\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memmap_path='/mnt/Velocity_Vault/Autofocus/Dataset_Storage/'\n",
    "# train_size=355\n",
    "# patch_num=12\n",
    "# test_size=47\n",
    "# num_classes=49\n",
    "\n",
    "# train_dataset = np.memmap(memmap_path+\"train_dataset\", dtype=np.float64, mode='r', shape=(patch_num*train_size,128, 128,98))\n",
    "# train_truth = np.memmap(memmap_path+\"train_truth_one_hot\", dtype=int, mode='r', shape=(patch_num*train_size,num_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "memmap_path='/mnt/Velocity_Vault/Autofocus/Dataset_Storage/'\n",
    "train_size=355\n",
    "patch_num=12\n",
    "test_size=47\n",
    "num_classes=49\n",
    "\n",
    "set_size_org=train_size*patch_num\n",
    "set_size=3920\n",
    "\n",
    "train_dataset = np.memmap(memmap_path+\"resampled_dataset\", dtype=np.float64, mode='r', shape=(set_size,128, 128,98))\n",
    "train_truth = np.memmap(memmap_path+\"resampled_truth_one_hot\", dtype=int, mode='r', shape=(set_size,num_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memmap_path='/mnt/Velocity_Vault/Autofocus/Dataset_Storage/'\n",
    "# train_size=355\n",
    "# patch_num=12\n",
    "# ratio=5\n",
    "# test_size=47\n",
    "# num_classes=49\n",
    "\n",
    "# org_train_dataset = np.memmap(memmap_path+\"train_dataset\", dtype=np.float64, mode='r', shape=(patch_num*train_size,128, 128,98))\n",
    "# org_train_truth = np.memmap(memmap_path+\"train_truth_one_hot\", dtype=int, mode='r', shape=(patch_num*train_size,num_classes))\n",
    "\n",
    "# decreased_size=(train_size)//ratio\n",
    "\n",
    "# train_dataset = np.memmap(memmap_path+\"small_train_dataset\", dtype=np.float64, mode='w+', shape=(patch_num*decreased_size,128, 128,98))\n",
    "# train_truth = np.memmap(memmap_path+\"small_train_truth_one_hot\", dtype=int, mode='w+', shape=(patch_num*decreased_size,num_classes))\n",
    "\n",
    "# train_dataset=org_train_dataset[:patch_num*decreased_size]\n",
    "# train_truth=org_train_truth[:patch_num*decreased_size]\n",
    "\n",
    "# train_dataset.flush()\n",
    "# train_truth.flush()\n",
    "\n",
    "# train_size=decreased_size\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3920, 128, 128, 98)\n",
      "(3920, 49)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.shape)\n",
    "print(train_truth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "memmap_path='/mnt/Velocity_Vault/Autofocus/Dataset_Storage/'\n",
    "test_size=47\n",
    "num_classes=49\n",
    "\n",
    "test_dataset = np.memmap(memmap_path+\"test_dataset\", dtype=np.float64, mode='r', shape=(patch_num*test_size,128, 128,98))\n",
    "test_truth = np.memmap(memmap_path+\"test_truth\", dtype=int, mode='r', shape=(patch_num*test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/Installation/Virtual_Environment/Python3_11/lib/python3.11/site-packages/keras/src/applications/mobilenet_v2.py:299: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 98 input channels.\n",
      "  input_shape = imagenet_utils.obtain_input_shape(\n",
      "2025-01-20 01:31:24.044019: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:24.045891: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:24.047577: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:24.049432: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:24.051156: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:24.052855: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:24.054457: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:24.055963: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-20 01:31:24.057502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3608 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "def create_model(input_shape=(128, 128, 98), num_classes=49):\n",
    "    base_model = MobileNetV2(input_shape=input_shape, include_top=False, pooling='avg', weights=None)\n",
    "    x = Dense(256, activation='relu')(base_model.output)\n",
    "    outputs = Dense(num_classes, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def ordinal_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred),axis=1)\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=6.25e-6, beta_1=0.5, beta_2=0.999),\n",
    "    loss=ordinal_loss\n",
    ")\n",
    "\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=SGD(learning_rate=0.01, momentum=0.9),\n",
    "#     loss=ordinal_loss\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_config = model.get_config()\n",
    "# print(model_config)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3920\n",
      "8\n",
      "490\n",
      "653\n"
     ]
    }
   ],
   "source": [
    "# set_size=set_size_org\n",
    "batch_size = 8\n",
    "global_steps = 320000\n",
    "#512000\n",
    "steps_per_epoch = set_size // batch_size  \n",
    "epochs = global_steps // steps_per_epoch\n",
    "\n",
    "print(set_size)\n",
    "print(batch_size)\n",
    "print(steps_per_epoch)\n",
    "print(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataGenerator(Sequence):\n",
    "#     def __init__(self, x_set, y_set, batch_size):\n",
    "#         self.x, self.y = x_set, y_set\n",
    "#         self.batch_size = batch_size\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "#         batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "#         return batch_x, batch_y\n",
    "\n",
    "# train_gen = DataGenerator(train_dataset, train_truth, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 01:31:32.864755: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2025-01-20 01:31:32.982176: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-01-20 01:31:35.341817: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-01-20 01:31:35.563385: I external/local_xla/xla/service/service.cc:168] XLA service 0x78f15ca3aa30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-01-20 01:31:35.563407: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-01-20 01:31:35.583589: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1737316895.699670   44663 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9/490 [..............................] - ETA: 2:34 - loss: 0.2541"
     ]
    }
   ],
   "source": [
    "import numpy as np   \n",
    "\n",
    "model_path='/mnt/Velocity_Vault/Autofocus/Model/Model_V1/model'\n",
    "\n",
    "class CustomSaveCallback(Callback):\n",
    "    def __init__(self, save_epochs, save_path):\n",
    "        super().__init__()\n",
    "        self.save_epochs = save_epochs\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) in self.save_epochs:  # Check if the current epoch is in the list\n",
    "            self.model.save(f\"{self.save_path}_epoch_{epoch + 1}.keras\")\n",
    "\n",
    "# Specify the epochs where you want to save the model\n",
    "save_epochs = [(i+1)*50 for i in range(13)]\n",
    "\n",
    "custom_callback = CustomSaveCallback(save_epochs, model_path)\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, dataset, truth, batch_size=5):\n",
    "        self.dataset = dataset\n",
    "        self.truth = truth\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(len(self.dataset))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataset) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        batch_x = self.dataset[batch_indices]\n",
    "        batch_y = self.truth[batch_indices]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # np.random.shuffle(self.indices)\n",
    "        pass\n",
    "\n",
    "\n",
    "train_gen = DataGenerator(train_dataset, train_truth, batch_size=batch_size)\n",
    "\n",
    "hist=model.fit(train_gen, epochs=epochs,verbose=1,callbacks=[custom_callback])\n",
    "\n",
    "# hist=model.fit(train_dataset[:100], train_truth[:100],batch_size=3,epochs=epochs)\n",
    "\n",
    "model_path='/mnt/Velocity_Vault/Autofocus/Model/Model_V1.keras'\n",
    "model.save(model_path)  # Save in SavedModel format\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ordinal_loss(y_true, y_pred):\n",
    "#     y_true = tf.cast(y_true, tf.float32)\n",
    "#     return tf.reduce_mean(tf.square(y_true - y_pred),axis=1)\n",
    "\n",
    "# from tensorflow.keras.models import load_model\n",
    "# model_path='/mnt/Velocity_Vault/Autofocus/Model/Model_V1.keras'\n",
    "# model=load_model(model_path,custom_objects={'ordinal_loss': ordinal_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_dataset)\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions=np.zeros((47 * 12, 49), dtype=np.float64)\n",
    "\n",
    "\n",
    "for i in range(12):\n",
    "    test_temp=test_dataset[i*47:(i+1)*47]\n",
    "    pred_temp=model.predict(test_temp)\n",
    "    for j in range(47):\n",
    "        predictions[i*47+j]=pred_temp[j]\n",
    "\n",
    "print(predictions.shape)\n",
    "# pprint(predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#predictions=model.predict(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_positions(array):\n",
    "    # Find the index of the max value along each row\n",
    "    return np.argmax(array, axis=1)\n",
    "\n",
    "pred_truth=get_max_positions(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(array1, array2):\n",
    "    # Check if both arrays are the same shape\n",
    "    if array1.shape != array2.shape:\n",
    "        raise ValueError(\"Arrays must have the same shape\")\n",
    "    \n",
    "    # Compare the arrays and calculate the accuracy\n",
    "    correct_predictions = np.sum(array1 == array2)\n",
    "    total_elements = array1.size\n",
    "    \n",
    "    accuracy = correct_predictions / total_elements\n",
    "    return accuracy*100\n",
    "\n",
    "pred_test=calculate_accuracy(pred_truth,test_truth)\n",
    "\n",
    "print(\"Exact Correctness \\n\")\n",
    "\n",
    "print(\"\\nPredicted Truth vs Ground Truth - \",pred_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(test_truth)\n",
    "pprint(pred_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_deviation(predictions, ground_truth):\n",
    "    assert len(predictions) == len(ground_truth), \"Prediction and ground truth lists must have the same length.\"\n",
    "    \n",
    "    new_array = (ground_truth - predictions)\n",
    "    ma=np.max(new_array)\n",
    "    av=np.mean(new_array)\n",
    "    \n",
    "    # Compute squared errors\n",
    "    squared_errors = [(p - gt) ** 2 for p, gt in zip(predictions, ground_truth)]\n",
    "    \n",
    "    # Calculate mean of squared errors\n",
    "    mse = sum(squared_errors) / len(ground_truth)\n",
    "    \n",
    "    return ma,av,mse\n",
    "\n",
    "ma,av,mse=calculate_deviation(pred_truth,test_truth)\n",
    "\n",
    "print(\"Deviation Correctness - Prediction \\n\")\n",
    "\n",
    "print('\\nMax Deviation - ',ma)\n",
    "print('\\nAvg Deviation - ',av)\n",
    "print('\\nMean Square Deviation - ',mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def plot_occurrences(numbers):\n",
    "    \"\"\"\n",
    "    Plots a horizontal bar graph of the occurrences of elements in a list.\n",
    "\n",
    "    Parameters:\n",
    "        numbers (list): A list of numbers to analyze.\n",
    "    \"\"\"\n",
    "    # Count occurrences of each element\n",
    "    occurrences = Counter(numbers)\n",
    "    \n",
    "\n",
    "    # Extract keys (unique numbers) and their corresponding values (counts)\n",
    "    elements = list(occurrences.keys())\n",
    "    counts = list(occurrences.values())\n",
    "    print(np.mean(counts))\n",
    "\n",
    "    # Plot a horizontal bar graph\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.barh(elements, counts, color=\"skyblue\")\n",
    "    plt.xlabel(\"Occurrences\")\n",
    "    plt.ylabel(\"Elements\")\n",
    "    plt.title(\"Occurrences of Elements in the List\")\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_frame(pred):\n",
    "    \"\"\"\n",
    "    Plots a horizontal bar graph of the occurrences of elements in a list.\n",
    "\n",
    "    Parameters:\n",
    "        numbers (list): A list of numbers to analyze.\n",
    "    \"\"\"\n",
    "    # Count occurrences of each element\n",
    "    \n",
    "    ele=[i for i in range(len(pred))]\n",
    "    # Plot a horizontal bar graph\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.barh(ele, pred, color=\"skyblue\")\n",
    "    plt.xlabel(\"Occurrences\")\n",
    "    plt.ylabel(\"Elements\")\n",
    "    plt.title(\"Occurrences of Elements in the List\")\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "plot_frame(predictions[2])\n",
    "print(predictions)\n",
    "# print(np.sum(predictions, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
